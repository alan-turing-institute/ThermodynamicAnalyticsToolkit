////
#
#    ThermodynamicAnalyticsToolkit - explore high-dimensional manifold of neural networks
#    Copyright (C) 2018 The University of Edinburgh
#    The TATi authors, see file AUTHORS, have asserted their moral rights.
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
////

[[quickstart.simulation]]
Using module simulation
~~~~~~~~~~~~~~~~~~~~~~~

The `simulation` module has been designed explicitly for
ease-of-use.
Typically, everything is achieved through two or three commands: One to setup
TATi by handing it a dash of options, then calling a function to `fit()` or
`sample()`. In the very end of this quickstart we will learn how to implement
our first sampler using this interface.

For a more extensive description of the simulation module, we refer to its
link:#reference.simulation[reference section].

If we have installed the TATi package in the folder `/foo`, i.e. we have
a folder `TATi` with a file `simulation.py` residing in there, then we
probably need to add it to the `PYTHONPATH` as follows

---------------
PYTHONPATH=/foo python3
---------------

In this shell, we may import the sampling part of the package as
follows

---------------
import TATi.simulation as tati
---------------

This will import the `Simulation` interface class as the shortcut `tati` from
the file mentioned before. This class contains a set of convenience functions
that hides all the complexity of setting up of input pipelines and networks.
Accessing the loss function, gradients and alike or training and sampling can
be done in just a few keystrokes.

In order to make our own python scripts executable and know about the
correct (possibly non-standard) path to ThermodynamicAnalyticsToolkit, place
the following two lines at the very beginning of the script:

---------------
import sys
sys.path.insert(1,"<path_to_TATi>/lib/python3.5/site-packages/")
---------------

where +<path_to_TATi>+ needs to be replaced by our specific
installation path and +python3.5+ needs to be replaced if we are using a
different python version. However, for the examples in this quickstart tutorial
it is not necessary if we use +PYTHONPATH+.

[[quickstart.simulation.notation]]
Notation
^^^^^^^^

In the following, we will use the following notation:

- dataset: latexmath:[$D = \{X,Y\}$] with features latexmath:[$X=\{x_d\}$] and labels
latexmath:[$Y=\{y_d\}$]
- batch of the dataset: latexmath:[$D_i=\{X_i, Y_i\}$]
- network parameters: latexmath:[$w=\{w_1, \ldots, w_M\}$]
- momenta of network parameters: latexmath:[$p=\{p_1, \ldots, p_M\}$]
- neural network function: latexmath:[$F_w(x)$]
- loss function: latexmath:[$L_D(w) = \sum_i l(F_w(x_i), y_i)$] with a loss
latexmath:[$l(x,y)$]
- gradients: latexmath:[$\nabla_w L_D(w)$]
- Hessians: latexmath:[$H_{ij} = \partial_{w_i} \partial_{w_j} L_D(w)$]

[[quickstart.simulation.general]]
Instantiating TATi
^^^^^^^^^^^^^^^^^^

The first thing in all the following example we will do is instantiate the
`tati` class.

[source,python]
----
import TATi.simulation as tati

nn = tati(
  # comma-separated list of options
)
----

Although it is the `simulation` module, we "nickname" it `tati` in the following
and hence will simply refer to this instance as `tati.`

This class takes a list of options in its construction or `__init__()` call.
These options inform it about the dataset to use, the specific network topology,
what sampler or optimizer to use and its parameters and so on.

To see how this works, we will first need a dataset to work on.

NOTE: All of the examples below can also be found in the folders
+doc/userguide/python+, +doc/userguide/simulation+, and +doc/userguide/simulation/complex+.

[[quickstart.simulation.general.help_options]]
Help on Options
+++++++++++++++

`tati` has quite a number of options that control its behavior. we can
request help to a specific option.
Let us inspect the help for `batch_data_files`:

[source,python]
---------------
>>> from TATi.simulation as tati
>>> tati.help("batch_data_files")
Option name: batch_data_files
Description: set of files to read input from
Type       : list of <class 'str'>
Default    : []
---------------

This will print a description, give the default value and expected type.

Moreover, in case we have forgotten the name of one of the options.

[source,python]
---------------
>>> from TATi.simulation as tati
>>> tati.help()
averages_file:             CSV file name to write ensemble averages information such as average kinetic, potential, virial
batch_data_file_type:      type of the files to read input from
 <remainder omitted>
---------------

This will print a general help listing all available options.

Use `get_options()` to get a dict of all options or to request the currently set
value of a specific option. Moreover, use `set_options()` to modify them.

[source,python]
---------------
include::simulation/get_options.py[]
---------------

[[quickstart.simulation.setup]]
Setup
^^^^^

In the following we will first be creating a dataset to work on. This example
code will be the most extensive one. All following ones are rather short and
straight-forward.

[[quickstart.simulation.setup.writing_data]]
Preparing a dataset
+++++++++++++++++++

Therefore, let us prepare the dataset, see the Figure link:#quickstart.dataset[Dataset],
for our following experiments.

At the moment, datasets are parsed from Comma Separated Values (CSV)
or Tensorflow's own TFRecord files or can be provided in-memory from numpy
arrays. In order for the following examples on optimization and sampling to
work, we need such a data file containing features and labels.

TATi provides a few simple dataset generators contained in the class
`ClassificationDatasets`.

One option therefore is to use the TATiDatasetWriter that provides access to
`ClassificationDatasets`, see link:#quickstart.cmdline.writing_dataset[Writing a dataset].
However, we can do the same using python as well. This should give us an idea
that we are not constrained to the `simulation` part of the Python interface,
see the reference on the general Python interface where we go through the
same examples without importing `simulation`.

[source,python]
---------------
include::python/writing_data.py[]
---------------

[WARNING]
The labels need to be integer values. Importing will fail if they are not.

After importing some modules we first fix the numpy seed to 426 in order
to get the same items reproducibly. Then, we first create 500 items
using the `ClassificationDatasets` class from the *TWOCLUSTERS* dataset with
a random perturbation of relative 0.01 magnitude. We shuffle the dataset as the
generators typically create first items of one label class and then items of
the  other label class. This is not needed here as our 'batch_size' will equal
the dataset size but it is good practice generally.

[NOTE]
The class `ClassificationDatasets` mimicks the dataset examples that can also
be found on the link:https://playground.tensorflow.org/[Tensorflow playground].

Afterwards, we write the dataset to a simple CSV file with columns "x1", "x2",
and "label1" using a helper function contained in the `TATi.common` module.

[CAUTION]
The file `dataset-twoclusters.csv` is used in the following examples, so keep
it around.

This is the very simple dataset we want to learn, sample from and exlore in the
following.

[[quickstart.simulation.setup.setting_up_network]]
Setting up the network
++++++++++++++++++++++

Let's first create a neural network. At the moment of writing TATi is
constrained to multi-layer perceptrons but this will soon be extended to
convolutional and other networks.

Multi-layer perceptrons are characterized by the number of layers, the
number of nodes per layer and the output function used in each node.

[source,python]
---------------
include::simulation/setting_up_network.py[]
---------------

In the above example, we specify a neural network of two hidden layers,
each having 8 nodes. We use the "rectified linear" activation function
for these nodes. The output nodes are activated by a linear function. At the
end, we print the number of parameters, i.e. latexmath:[$M=105$] for the set of
parameters latexmath:[$w=\{w_1, \ldots, w_M\}$].

The network's weights are initialized randomly in the interval [-0.5,0.5] and
the biases are set to 0.1 (small, non-zero values).

Let us briefly highlight the essential options (a full and up-to-date list
is given in the API reference in the class `PythonOptions`):

- `input_columns`: This option allows to add an additional layer after the
input that selects a subset of the input nodes and additionally modifies them,
e.g., by passing through a sine function. Example: `input_columns=["sin(x1), x2^2"]`
- `input_dimension`: This is the number of input nodes of the network, one node
per dimension of the supplied dataset. Example `input_dimension=10`
- `output_activation`: Defines the activation function for the output layer.
Example: `output_activation="sigmoid"`
- `output_dimension`: Sets the number of output nodes. Example: `output_dimension=1`
- `hidden_activation`: Defines the common activation function for all hidden
layers. Example: `hidden_activation="relu6"`
- `hidden_dimension`: Gives the hidden layers and the nodes per layer by giving
a list of integers. Example: `hidden_dimension=[2,2]` defines two hidden layers,
each with 2 nodes.
- `loss`: Sets the loss function latexmath:[$l(x,y)$] to use. Example:
`loss="softmax_cross_entropy"`

A complete set of all actications functions can be obtained.

[source,python]
---------------
include::simulation/get_activations.py[]
---------------

Similar, there is a also a list of all available loss functions.

[source,python]
---------------
include::simulation/get_losses.py[]
---------------

[NOTE]
====
At the moment it is not possible to set different activation functions
for individual nodes or between hidden layers.
====

[NOTE]
====
Note that (re-)creating the `tati` instance  will always reset the
computational graph of tensorflow in case we need to add nodes.
====

[[quickstart.simulation.setup.freezing_parameters]]
Freezing network parameters
+++++++++++++++++++++++++++

Sometimes it might be desirable to freeze parameters during training or
sampling. This can be done as follows:

[source,python]
---------------
include::simulation/fix_parameter.py[]
---------------

This is same code as before when
link:#quickstart.simulation.setup.setting_up_network[setting up the network]
the only exception is the additional option 'fix_parameters'.

Note that we give the parameter's name in full tensorflow
namescope: "output" for the network layer, "biases" for the weights ("weights"
alternatively) and "Variable:0" is fixed (as it is the only one). This is
followed by a comma-separated list of values, one for each component.

====
[NOTE]

Single values cannot be frozen but only entire weight matrices or bias
vectors per layer at the moment. As each component has to be listed, at the
moment this is not suitable for large vectors.
====

[[quickstart.simulation.simple_evaluation]]
Evaluating loss and gradients
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Having created the dataset and explained how the network is set up, we know
see how to evaluate the loss and the gradients.

The main idea of the `simulation` module is to be used as a simplified
interface to access the loss and the gradients of the neural network without
having to know about the internal of the neural network. In other words, we
want to treat it as an abstract high-dimensional function, depending
implicitly on the weights and explicitly on the dataset. To this end, the
weights and biases are represented as one linearized vector. Moreover, we have
another abstract high-dimensional function, the loss that depends explicitly
on the weights and implicitly on the dataset, whose derivative (the gradients
with respect to the parameters) is available as a numpy array, see also the
section link:#quickstart.simulation.notation[Notation].

In the following example we set up a simple fully-connected hidden network
and evaluates loss and then the associated gradients.

[source,python]
---------------
include::simulation/complex/eval_loss_gradient.py[]
---------------

Again, we set up the network as before, here it is a single-layer perceptron
as the default value for `hidden_dimension` is 0. Next, we evaluate the loss
latexmath:[$L_D(w)$] using `nn.loss()` and the gradients latexmath:[$\nabla_w L_D(w)$]
using `nn.gradients()`, returning a vector with the gradient per degree of
freedom of the network.

[NOTE]
Under the hood it is a bit more complicated: loss and gradients are inherently
connected. If 'batch_size' is chosen smaller than the dataset dimension,
naive evaluation of first loss and then gradients in two separate function calls
would cause them to be evaluated on different batches. Depending on the size of
the batch, the gradients will then not belong the to the respective loss
evaluation and vice versa.
Therefore, loss, accuracy, gradients, and hessians latexmath:[$H_{ij}$] (if
'do_hessians' is True) are cached. Only when one of them is evaluated for the
second time (e.g., inside the loop body on the next iteration), then the next
batch is used. This makes sure that calling either `loss()` first and then
`gradients()` or the other way round yields the same values connected to the
same dataset batch.
In essence, just don't worry about it!

As we see in the above example, `tati` forms the general interface class that
contains the network along with the dataset and everything in its internal
state.

This is basically all the access we need in order to use our own optimization,
sampling, or exploration methods in the context of neural networks in a
high-level, abstract way.

[[quickstart.simulation.optimizing]]
Optimizing the network
^^^^^^^^^^^^^^^^^^^^^^

Let us then start with optimizing the network, i.e. learning the data.

[source,python]
---------------
include::simulation/complex/optimize.py[]
---------------

Again all options are set in the init call to the interface. These options
control how the optimization is performed, what kind of network is created,
how often values are stored, and so on.
Next, we call `nn.fit()` to perform the actual training for the chosen number
of training steps ('max_steps'). We obtain a single return structure within
which we find three `pandas` dataframes: run info, trajectory, and averages.
Of each we print the last ten values.

Let us quickly go through each of the new parameters:

* 'batch_size'
+
sets the subset size of the data set looked at per training step,
latexmath:[$|D_i|=|\{X_i, Y_i\}|$], if smaller than dimension, then we add
stochasticity/noise to the training but for the advantage of smaller runtime.

* 'learning_rate'
+
defines the scaling of the gradients in each training step, i.e. the
learning rate. Values too large may miss the minimum, values too small
need longer to reach it. For automatic picking of the *learning_rate*, use
'BarzilaiBorweinGradientDescent'. This however is not compatible with
mini-batching at the moment as it requires exact gradients.

* 'max_steps'
+
gives the amount of training steps to be performed.

* optimizer
+
defines the method to use for training. Here, we use Gradient Descent
(in case 'batch_size' is smaller than dimension, then we actually have
Stochastic Gradient Descent). Alternatively, you
'BarzilaiBorweinGradientDescent' is also available. There the secant equation
is solved in a minimal l2 error fashion which allows to automatically determine
a suitable step width. This *learning_rate* is then only used for the initial
guess and as a fall-back.

* 'seed'
+
sets the seed of the random number generator. We will still have full
randomness but in a deterministic manner, i.e. calling the same
procedure again will bring up the exactly same values.

TIP: In case we need to change these options elsewhere in our python code,
use `set_options()`.

WARNING: `set_options()` may need to reinitialize certain parts of `tati` s
internal state depending on what options we choose to reset. Keep in mind
that modifying the network will reinitialize all its parameters and other
possible side-effects. See `simulation._affected_map` in
+src/TATi/simulation.py+ for an up-to-date list of what options affects what
part of the state.

For these small networks the option 'do_hessians' might be useful which will
compute the hessian matrix at the end of the trajectory and use the
largest eigenvalue to compute the optimal step width. This will add
nodes to the underlying computational graph for computing the components
of the hessian matrix. However, we will not do so here.

[CAUTION]
====
The creation of these hessian evaluation nodes (not speaking of their
evaluation) is a latexmath:[$O(N^2)$] process in the number of parameters of the
network N. Hence, this should only be done for small networks and on purpose.
====

After the options have been provided, the network is initialized internally
and automatically, we then call `fit()` which performs the training and returns
a structure containing runtime info, trajectory, and averages as a pandas
`DataFrame`.

In the following section on link:#quickstart.simulation.sampling[sampling] we will
explain what each of these three dataframes contains exactly.

TIP: In case more output of what is actually going on in each training step is
needed, set `verbose=1` or even `verbose=2` in the options when constructing
`tati()`.

Let us have a quick glance at the decrease of the loss function over the steps
by using `matplotlib`. In other words, let us look at how effective the training
has been.

[[quickstart.simulation.optimizing.plot_optimize]]
[source,python]
---------------
include::python/plot_optimize.py[]
---------------

The loss per step is contained in both the run info and the trajectory dataframe
in the column 'loss'.

The graph should look similar to the one obtained with `pgfplots` here (see
https://sourceforge.net/pgfplots).

.Loss history: Behavior of the loss over the optimization run
image::pictures/optimization-step_loss.png[{basebackend@docbook:scaledwidth="60%":width=500}]

As we see the loss has decreased quite quickly down to 1e-3. Go and have a
look at the other columns such as accuracy. Or try to visualize the change
in the parameters (weights and biases) in the trajectories dataframe. See
link:https://pandas.pydata.org/pandas-docs/stable/10min.html[10 Minutes to pandas]
if we are unfamiliar with the `pandas` module, yet.

Obviously, we did not use a different dataset set for testing the effectiveness
of the training which should commonly be done. This way we cannot check whether
we have overfitted or not. However, our example is trivial by design and the
network too small to be prone to overfitting this dataset.

Nonetheless, we show how to supply a different dataset and evaluate loss and
accuracy on it.

[[quickstart.simulation.sampling.supply_dataset]]
Provide our own dataset
++++++++++++++++++++++++

We can directly supply our own dataset, e.g., from a numpy array residing in
memory. See the following example where we do not generate the data but parse
them from a CSV file instead of using the pandas module.

[source,python]
---------------
include::simulation/complex/supply_dataset.py[]
---------------

The major difference is that `batch_data_files` in `tati()` is now empty and
instead we simply later assign `nn.dataset` a numpy array to use. Note that we
could also have supplied it directly with the filename +dataset-twoclusters.csv+,
i.e. `nn.dataset = "dataset-twoclusters.csv"`.
In this example we have parsed the same file as the in the previous section
into a numpy array using the pandas module. Natually, this is just one way of
creating a suitable numpy array.

At the end we have stated `loss()` and the `score()`. While the loss is simply
the output of the training function, the score gives the accuracy in a
classification problem setting: We compare the label given in the dataset with
the label predicted by the network and take the average over the whole dataset
(or its mini-batch if `batch_size` is used). For multi-labels, we use the
largest entry as the label in multi classification.

NOTE: Input and output dimensions are directly deduced from the the tuple sizes.

NOTE: The nodes in the input layer can be modified using `input_columns`, e.g.,
`input_columns=["x1", "sin(x2)", "x1^2"]`.

[[quickstart.simulation.sampling]]
Sampling the network
^^^^^^^^^^^^^^^^^^^^

Typically, as preparation to a sampling run, one would optimize or equilibrate
the initially random positions first. This might be considered a specific way
of initializing parameters.

[NOTE]
.Statistical background
================
In general, when sampling from a distribution (to compute empirical averages
for example), one wants to start 'close to equilibrium', i.e. from states which
are of high probability with respect to the target distribution (therefore
the minima of the loss). The initial optimization procedure is therefore a
first guess to find such states, or at least to get close to them.
================

However, let us first ignore this good practice for a moment and simply look
at sampling from a random initial place on the loss manifold. We will come
back to it later on.

[source,python]
---------------
include::simulation/complex/sample.py[]
---------------

Here, the 'sampler' setting takes the place of the 'optimizer' before as
it states which sampling scheme to use. See <<reference.samplers>> for a
complete list and their parameter names. Apart from that the example code
is very much the same as in the example involving `fit()`.

NOTE: In the context of sampling we use 'step_width' in place of 'learning_rate'.

Again, we produce a single data structure that contains three data frames: run
info, trajectory, and averages. Trajectories contains among others all
parameter degrees of freedom latexmath:[$w=\{w_1, \ldots, w_M\}$] for each step
(or 'every_nth' step). Run info contains loss, accuracy, norm of gradient,
norm of noise and others, again for each step. Finally, in averages we compute
running averages over the trajectory such as average (ensemble) loss, averag
kinetic energy, average virial, see link:#reference.concepts[general concepts].

Take a peep at `sampling_data.run_info.columns` to see all columns in the
run info dataframe (and similarly for the others.)

For the running averages it is advisable to skip some initial ateps
('burn_in_steps') to allow for some burn in time, i.e. for kinetic energies to
adjust from initially zero momenta.

Some columns in averages and in run info depend on whether the sampler
provides the specific quantity, e.g. link:#reference.samplers.sgld[SGLD] does
not have momentum, hence there will be no average kinetic energy.

[[quickstart.simulation.sampling.priors]]
Using a prior
+++++++++++++

We may add a prior to the sampling. At the current state two kinds of
priors are available: wall-repelling and tethering.

The options 'prior_upper_boundary' and 'prior_lower_boundary' give the admitted
interval per parameter. Within a relative distance of 0.01 (with respect to
length of domain and only in that small region next to the specified boundary)
an additional force acts upon the particles to drives them back into the desired
domain. Its magnitude increases with distance to the covered inside the boundary
region. The distance is taken to the poour of 'prior_power'. The force
is scaled by 'prior_factor'.

In detail, the prior consists of an extra force added to the time integration
within each sampler. We compute its magnitude as

[latexmath]
++++
\Theta(\frac{||w - \pi||}{\tau}-1.) \cdot a ||x - \pi||^n
++++

where *w* is the position of the particle, *a* is the 'prior_factor',
latexmath:[$\pi$] is the position of the boundary ('prior_upper_boundary'
latexmath:[$\pi_{ub}$] or 'prior_lower_boundary' latexmath:[$\pi_{lb}$]), and *n*
is the `prior_power`. Finally, the force is only in effect within a distance of
latexmath:[$\tau = 0.01 \cdot || \pi_{ub} - \pi_{lb} ||$] to either boundary by
virtue of the Heaviside function latexmath:[$\Theta()$].
Note that the direction of the force is such that it always points back into
the desired domain.

If upper and lower boundary coincide, then we have the case of
tethering, where all parameters are pulled inward to the same point.

At the moment applying prior on just a subset of particles is not supported.

[NOTE]
====
The prior force is acting directly on the variables. It does not modify
momentum. Moreover, it is a force! In other words, it depends on step
width. If the step width is too large and if the repelling force
increases too steeply close to the walls with respect to the normal
dynamics of the system, it may blow up. On the other hand, if it is too weak,
then particles may even escape.
====

[[quickstart.simulation.sampling.optimize_then_sample]]
First optimize, then sample
+++++++++++++++++++++++++++

As we have already alluded to before, optimizing before sampling is the
*recommended* procedure. In the following example, we concatenate the two.
To this end, we might need to modify some of the options in between. Let us have
a look, however with a slight twist.

The dataset shown in Figure link:#quickstart.dataset[Dataset] can be even
learned by a simpler network: only one of the input nodes is actually
needed because of the symmetry.

Hence, we look at such a network by using 'input_columns' to only use input
column "x1" although the dataset contains both "x1" and "x2".

Moreover, we will add a hidden layer with a single node and thus obtain a
network as depicted in Figure link:#quickstart.network[Network].
We add this hidden node to make the loss manifold a little bit more
interesting.

Additionally, we fix the biases to *0* for both the hidden layer bias and the
output bias. Effectively, we have two degrees of freedom left. This is not
strictly necessary but allows to plot all degrees of freedom at once.

Finally, we add a link:#quickstart.simulation.sampling.priors[prior].

[source,python]
---------------
include::simulation/complex/optimize_sample.py[]
---------------

NOTE: Setting 'every_nth' large enough is essential when playing around with
small networks and datsets as otherwise time spent writing files and adding
values to arrays will dominate the actual neural network computations by far.

As we see, some more options have popped up in the `__init__()` of the
simulation interface: 'fix_parameters' is explained in section
<<quickstart.simulation.setup.freezing_parameters>>,
'hidden_dimension' which is a list of the number of
hidden nodes per layer, 'input_columns' which contains a list of strings,
each giving the name of an input dimension (indexing starts at 1), and all
sorts of 'prior_...' that define a wall-repelling prior, again see
[[quickstart.simulation.priors]] for details. This will keep parameter values
within the interval of [-2,2]. Last but not least, 'trajectory_file' writes
all parameters per 'every_nth' step to this file.

Then, we call `nn.fit()` to perform the training as before.

Next, we need to change the number of steps, set a sampling step width
and add the sampler (which might depend on additional parameters, see <<reference.samplers>>
). This is done by calling `nn.set_options()`.

Having set the stage for the sampling, we commence it by `nn.sample()`.

At the very end we again obtain the data structure containing the `pandas`
DataFrame containing runtime information, trajectory, and averages as its
member variables.

WARNING: This time we need the trajectory file for the upcoming analysis. Hence,
we write it to a file using the 'trajectory_file' option. Keep the file around
as it is needed in the following.

Let us take a look at the two degrees of freedom of the network, namely the two
weights, where we plot one against the other similarly to the
link:#quickstart.simulation.optimizing.plot_optimize[Sampled weights] before.

[[quickstart.simulation.analysis.optimize_sample.weights]]
.Sampled weights: Plot of first against second weight.
image::pictures/weights.png[align="center",{basebackend@docbook:scaledwidth="40%":width=400}]

First of all, take note that the prior (given 'prior_force' is strong enough
with respect to the chosen 'inverse_temperature') indeed retains both parameters
within the interval [-2,2] as requested.

Compare this to the Figure link:#quickstart.landscape.loss[Loss manifold]. we
will notice that this trajectory (due to the large enough temperature) has also
jumped over the ridge around the origin.

NOTE: To bound the runtime of this example, we have set the parameters such that
we obtain a good example of a barrier-jumping trajectory. The original values
from the introduction are obtained when we reduce the 'inverse_temperature'
to *4.* and increase 'max_steps' to *20000* (or even more) if we do not mind
waiting a minute or two for the sampling to execute.

[[quickstart.simulation.analysis]]
Analysing trajectories
^^^^^^^^^^^^^^^^^^^^^^

Analysis involves parsing in run and trajectory files that we have written
during optimization and sampling runs. Naturally, we could also perform this
on the `pandas` dataframes directly, i.e. sampling and analysis in the same
python script. However, for completeness we will read from files in the
examples of this section.

The analysis functionality has been split into specific operations such as
computing averages, computing the covariance matrix or generating a diffusion
map analysis. See the source folder +src/TAT/analysis+, for all contained
modules therein each represent such an operation.

In the following we will highlight just a few of them.

All these analysis operations are also possible through `TATiAnalyser`, see
+tools/TATiAnalyser.in+ in the repository.

[[quickstart.simulation.analysis.averages]]
Average parameters
++++++++++++++++++

[source,python]
---------------
include::python/analyse_averages.py[]
---------------

We use the helper class `ParsedTrajectory` which takes a trajectory file and
heeds additional options such as neglecting burn in steps or taking only
'every_nth' step into account.
Next, we instantiate the `AverageTrajectoryWriter` module. It computes
the averages and variance of each parameter, whose result we print.

NOTE: This is only useful if the trajectory remains within a single minimum.

[[quickstart.simulation.analysis.covariance]]
Covariance
++++++++++

The covariance matrix of the trajectory gives the joint variability of any two
of its components. Its eigenvalues give a notion the magnitude between
directions with large gradients and between directions with small gradients.

In sampling this is important as directions with small gradients take longer
to be explored, see the concept of Integrated Autocorrelation Time (IAT) in
section <<quickstart.sampling.iat>>.

NOTE: If we look at the covariance of a distribution, we essentially replace it by
a Gaussian mixture model defined by this covariance matrix.

Let us compute the covariance using the analysis module `Covariance`.

[source,python]
---------------
include::python/analyse_covariance.py[]
---------------

Note the helper class `ParsedTrajectory` which takes a trajectory file and
heeds additional options such as neglecting burn in steps or taking only
'every_nth' step into account.
This instance is handed to the `Covariance` class whose `compute()` function
performs the actual analysis. Typicallay, all analysis operations have such a
`compute()` function.
Again, we plot the result.

[[quickstart.simulation.analysis.covariance.figure]]
.Covariance: Trajectory plotted in the directions of two covariance eigenvectors
image::pictures/covariance.png[align="center",{basebackend@docbook:scaledwidth="40%":width=400}]

We have depicted the weights in the direction of each eigenvector. Essentially,
we get a rotated view of the trajectory in <<quickstart.simulation.analysis.optimize_sample.weights>>
where the *x* direction represents the dominant change.

[[quickstart.simulation.analysis.diffusion_map]]
Diffusion Map
+++++++++++++

Diffusion maps are a technique for unsupervised learning introduced by
<<Coifman2006>>.

[quote, pydiffmap, https://pydiffmap.readthedocs.io/en/master/theory.html]
_____
Diffusion maps is a dimension reduction technique that can be used to discover
low dimensional structure in high dimensional data. It assumes that the data
points, which are given as points in a high dimensional metric space, actually
live on a lower dimensional structure. To uncover this structure, diffusion
maps builds a neighborhood graph on the data based on the distances between
nearby points. Then a graph Laplacian L is constructed on the neighborhood
graph. Many variants exist that approximate different differential operators.
_____

link:https://github.com/DiffusionMapsAcademics/pyDiffMap[pydiffmap] is an
excellent Python package that performs the analysis which consists of computing
the eigendecomposition of a sparse neighborhood graph where the Euclidean
metric is used as distance measure. If it is installed (using `pip`), it is
used for this type of analysis (use `method=pydiffmap` in this case).

In a nutshell, the eigenvectors of the diffusion map kernel give us the main
directions on our trajectory. They represent collective variables learned
from the trajectory.

Let us take a look at the eigenvectors from our trajectory that we have sampled
just before.

[source,python]
---------------
include::python/analyse_diffmap.py[]
---------------

We should then obtain the Figure link:#quickstart.simulation.analysis.diffusion_map.eigenvectors[Diffusion map analysis].

[[quickstart.simulation.analysis.diffusion_map.eigenvectors]]
.Diffusion map analysis: Plot of first weight against second weight, colored by first eigenvector of the diffusion map kernel
image::pictures/eigenvectors.png[align="center",{basebackend@docbook:scaledwidth="25%":width=200}]

NOTE: The true first eigenvector is constant and is therefore dropped in the
function `compute_diffusion_maps()`.

Keep in mind that the ridge is at the origin and there are two hperbolic basins
on either side in the all-positive and all-negative orthant of the 2d space.
We see that as we color the trajectory points by the value of the dominant
eigenvector, the path between these two minima is highlighted: from
light green to dark blue.

The eigenvector gives a direction: From the top right to the bottom left and
therefore from one minimum basin to the other.

The eigenvector component give the implicit evaluation of the collective
variable function at each trajectory point, i.e. latexmath:[$e_i = \xi(x_i)$],
where latexmath:[$\xi(x)$] is the collective variable and latexmath:[$e_i$] is the
i-th component and latexmath:[$x_i$] the i-th trajectory point.

The eigenvectors of the diffusion map kernel also give us a mean to assess
distances between trajectory points by looking at the difference in values,
latexmath:[$|e_i - e_j|$].
This is the so-called _diffusion distance_. It tells us how difficult it is to
diffuse from one point to the other.

The main difference between the covariance and diffusion maps is that the latter
gives a non-linear mapping which is much more powerful.

Conclusion
^^^^^^^^^^

This has been the quickstart introduction to the `simulation` interface.

If we want to take this further, we recommend reading how to implement a
link:#reference.implementing_sampler[GLA2 sampler] using this module.

If we still want to take it further, then we need to look at the
ifdef::basebackend-docbook[ programmer's guide ]
ifdef::basebackend-html[ link:programmersguide.html[programmer's guide] ]
that should accompany our installation.
