////
#
#    ThermodynamicAnalyticsToolkit - explore high-dimensional manifold of neural networks
#    Copyright (C) 2018 The University of Edinburgh
#    The TATi authors, see file AUTHORS, have asserted their moral rights.
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
////

Tensorflow Flaws
----------------

It may be thought a little too much to dedicate a whole chapter to the
potential flaws in a framework that forms the basis of this software.
However, this particular framework has given me so much hardship and
failed in such unexpected ways that I have to make a list.

Note that this list is up-to-date with respect to the tests employed in
the code and is currently focused at tensorflow version 1.4

Most of issues simply made it hard to have reproducible runs which made
it diffult to maintain my testsuite. Moreover, most of them are made on
purpose for the sake of speed over deterministic behavior.
// This makes me in turn really wonder whether the tensorflow guys actually have a testsuite (or whether it justs consists of unit tests).

* Non-deterministic `reduce_sum`
+
See the https://github.com/tensorflow/tensorflow/issues/3103[issue] at
Github. Non-deterministic is obviously faster than deterministic, so
that's what they are going for. Sadly, no determinstic alternative for
calculating norms of 1-dimensional tensors or scalar products is
offered. This is very hurtful for reproducibility. The current
workaround is to set `inter_op_thread` to one, eliminating any use of
multiple cores.

* `tf.set_global_seed` not useful
+
This is working as intended: it sets the global seed in such a way that
all operations requiring randomness derive their seed in a deterministic
fashion from it. And this is valid as long as it is _exactly_ the same
graph. If just a single node is added that does not even need to be
relevant for the operation, all seeds will change because the derivation
of seeds probably depends on some random order of nodes and not on the
name of the node or any other unique property.

* `tf.float64` is flawed
+
I encountered issues with precision when ascertaining theoretical
properties of the samplers. One remedy I though might solve the issue
was to switch from tf.float32 to tf.float64, i.e. from 1e-8 to 1e-18
internal floating point precision.
+
What I found was that suddenly I could not recover the theoretical
properties any more. Even simple sampling (i.e. central limit theorem
and expected convergence rates of latexmath:[$\frac 1 {sqrt(n)}$] would not
bring up slopes of -0.5 as expected in log-log plots but also -0.4.
+
I went to great length to check that all values are tf.float64. If I had
forgotten one, either the internal type checker would admonish it, or
the precision should just be the one I had with tf.float32. However, the
quality of the values had changed. My only guess is that there must be
some weird bug hidden deep in the C parts of the tensorflow code.

* Parsing from CSV file despite caching tenfold slower
+
With tensorflow 1.4 the Dataset module arrived (no longer being
"contrib") and I happily switched to this as means of constructing my
input pipeline. So far, I had just been looking at small test datasets
which fit in memory without issues. As the datasets were so small, I did
not expect any much slowing down of my code switching to parsing CSV
files and feeding them.
+
However, both the old "queues" input pipeline and the new "Dataset"
pipeline (the latter even with caches) experienced a tenfold decrease of
runtime with respect to in/memory.
+
I must admit though that the Dataset module at least made it possible to
let the user decide between in-memory storing and file parsing.

* `tf.if` conditional working in funny way
+
For the Hamiltonian Monte Carlo sampler an "if" block is required
inside the gradient evaluation that decides on whether the current short
trajectory run using Hamiltonian Dynamics is accepted or rejected. When
I tried make this work, I failed utterly, until I hit this
https://stackoverflow.com/a/37064128[answer] on stackoverflow. In a
comment even one from the tensorflow team admits that he finds this
behavior confusing.

* Shuffling (in queues) shuffles over all repeated datasets causing
duplicate items.
+
I gues this is for speed reasons as well but it is really a pain in the
arse. I guess the reason is a reshuffled dataset in every epoch, hence
the reshuffle over all repeated sets instead of reshuffling at the start
of the epoch. Probably it is simpler to implement with really large
datasets in multiple files.
+
However, for small datasets suddenly your gradients change (not using
mini-batches) because one element is missing as another is in the set
twice. Again, bad for reproducibility.

* `tf.concat` dropping variable character
+
This is more of a nuisance but a painful one that has quite strong effects on
the efficiency of the *simulations* interface part: You cannot simply
concatenate four variable tensors and then set them all using a single
placeholder of the right dimension as the "variable" character is lost in
the concatenation. It can only be read, see link:https://stackoverflow.com/questions/47699569[stackoverflow].
See also this related link:https://github.com/tensorflow/tensorflow/issues/1723[issue].
