<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
  <!ENTITY dataset_two_clusters SYSTEM "pictures/dataset_two_clusters.png" NDATA PNG>
  <!ENTITY simple_single_layer_perceptron SYSTEM "pictures/simple_single_layer_perceptron.png" NDATA PNG>
  <!ENTITY optimization_step_loss SYSTEM "pictures/optimization-step_loss.png" NDATA PNG>
  <!ENTITY neuralnetwork_permutation_symmetry SYSTEM "pictures/neuralnetwork_permutation_symmetry.png" NDATA PNG>
  <!ENTITY losslandscape_permutation_symmetry SYSTEM "pictures/losslandscape_permutation_symmetry.png" NDATA PNG>
]>
<book 
  xmlns="http://docbook.org/ns/docbook" 
  xmlns:xlink="http://www.w3.org/1999/xlink" 
  xmlns:param="http://www.w3.org/1999/param" 
  xmlns:xi="http://www.w3.org/2001/XInclude" 
  xmlns:svg="http://www.w3.org/2000/svg" 
  xmlns:mml="http://www.w3.org/1998/Math/MathML" 
  xmlns:html="http://www.w3.org/1999/xhtml" 
  xmlns:db="http://docbook.org/ns/docbook" version="5.0">
<info>
  <title>ThermodynamicAnalyticsToolkit</title>
  <subtitle>Manual version <xi:include  href="version.txt"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></subtitle>
  <author>
      <personname>
        <firstname>Frederik</firstname>
        <surname>Heber</surname>
      </personname>
      <email>frederik.heber@gmail.com</email>
      <affiliation>
        <orgname>The University of Edinburgh</orgname>
        <address>School of Mathematics, 5613, JCMB, Peter Guthrie Tait Road, Edinburgh, EH9 3FD </address>
      </affiliation>
  </author>
  <copyright>
    <holder>The University of Edinburgh, all rights reserved</holder>
    <year>2017-2018</year>
  </copyright>
   <cover>
        <para role="tagline">The Official Documentation for ThermodynamicAnalyticsToolkit</para>
        <mediaobject>
          <imageobject>
            <imagedata width="30%" scalefit="1." entityref="dataset_two_clusters"/>
          </imageobject>
        </mediaobject>
  </cover>
      <cover>
        <mediaobject>
          <imageobject>
            <imagedata width="30%" scalefit="1." entityref="dataset_two_clusters"/>
          </imageobject>
        </mediaobject>
        <para>ThermodynamicAnalyticsToolkit is a sampling-based approach to training 
        neural networks using TensorFlow </para>
        <para><citetitle>ThermodynamicAnalyticsToolkit: Manual</citetitle> is the…</para>
        <itemizedlist>
          <listitem>
    	      <para>A brief introduction to data-driven sampling in machine learning</para>
          </listitem>
          <listitem>
            <para>A guide to using ThermodynamicAnalyticsToolkit to perform sampling experiments</para>
          </listitem>
        </itemizedlist>
      </cover>
</info>

<xi:include href="bibliography.xml"/>

<xi:include href="glossary.xml"/>

  <chapter xml:id="introduction">
    <title xml:id="introduction.title">Introduction</title>
    <section xml:id="introduction.needtoknow">
      <title xml:id="introduction.needtoknow.title">Before you start</title>
      <para>In the following we assume that you, the reader, has a general 
      familiarity with neural networks. You should know what a classification
      problem is, what an associated dataset for (supervised) learning needs
      to contain. You should know about what weights and biases in a neural
      network are and what the loss function does. You should also have a
      trough idea of what optimization is and that gradients with respect to
      the chosen loss function can be obtained through so-called 
      backpropagation.
      </para>
      <para>If you are <emphasis>not</emphasis> familiar with the above
      terminology, then please first read <xref linkend="reference.concepts"/>.
      </para>
    </section>
    <section xml:id="introduction.whatis">
      <title xml:id="introduction.whatis.title">What is ThermodynamicAnalyticsToolkit?</title>
      <para>Typically, optimzation in neural network training employs methods 
      such as Gradient Descent, Stochastic Gradient Descent or derived methods
      using momentum such as ADAM and so on. The loss function itself may be
      convex, however, the loss manifold given a large dataset is not convex 
      in general. Hence, these methods will only find local minima. Therefore, 
      the eventual set of trained parameters of the neural network is not 
      optimal. Nonetheless, Neural networks, given enough data and processing 
      power, work marvelously and one may wonder why.
      </para>
      <para>The essential idea behind this program package is that we use
      sampling instead of optimization: we are not interested in the local 
      minimum closest to some random initial configuration and be done. 
      Instead we aim at finding all of the minima and all possible barriers 
      in between by treating the loss function as a high-dimensional potential
      and the weights and biases of the neural network as one-dimensional 
      particles in a stochastic differential equation, namely Langevin Dynamics.</para>
      <para>There is not need to panic: You do not need to know anything about 
      these kinds of equations when using the program. However, rest assured 
      that all statistical properties derived using trajectories obtained 
      through these equations are meaningful.</para>
      <para>The hope is to elucidate the marvel behind the wondrous 
      performance of neural networks, maybe to obtain even better 
      parametrizations or obtain the same in cheaper ways, and also to gather 
      means of optimizing the neural network's topology given a specific 
      dataset to train.</para>
      <para>In essence, this program suite provides samplers using 
      <link xlink:href="https://www.tensorflow.org/">TensorFlow</link> and
      analysis tools to extract specific statistical quantities from the 
      computed particle trajectories.</para>
      <para>It can be used both as python module and as stand-alone 
      command-line tools.</para>
    </section>
    <section xml:id="introduction.installation">
      <title xml:id="introduction.installation.title">Installation</title>
      <para>In the following we explain the installation procedure to get
      ThermodynamicAnalyticsToolkit up and running.</para>
      <section xml:id="introduction.installation.requirements">
        <title xml:id="introduction.installation.requirements.title">Installation requirements</title>
        <para>This program suite is implemented using python3 and the development
        mainly focused on Linux (development machine uses Ubuntu 16.04). At the
        moment other operation systems are not supported but may still work.</para>
        <para>It has the following non-trivial dependencies:</para>
        <itemizedlist>
          <listitem>TensorFlow: see below<uri>www.tensorflow.org</uri>, version 1.4 till currently 1.6 supported</listitem>
          <listitem>Numpy: see <uri>www.numpy.org</uri></listitem>
          <listitem>Pandas: see <uri>pandas.pydata.org</uri></listitem>
          <listitem>sklearn: see <uri>scikit-learn.org</uri></listitem>
        </itemizedlist>
        Note that most of these packages can be easily installed using either
        the repository tool (using some linux derivate such as Ubuntu), e.g.
        <programlisting>sudo apt install python3-numpy</programlisting>or via
        <command>pip3</command>, i.e.
        <programlisting>pip3 install numpy</programlisting>
        <para>Moreover, the following packages are not ultimately required but
        examples or tests may depend on them:</para>
        <itemizedlist>
          <listitem>matplotlib: see <uri>matplotlib.org</uri></listitem>
          <listitem>sqlite3: see <uri>www.sqlite.org</uri></listitem>
        </itemizedlist>
        <para>Finally, for the diffusion map analysis we recommend using the
        pydiffmap package, see 
        <uri>github.com/DiffusionMapsAcademics/pyDiffMap</uri>.</para>
        <para>In our setting what typically worked best was to use 
        <productname>anaconda</productname> in the following manner:</para>
        <programlisting>conda create -n tensorflow python=3.5 -y
  conda install -n tensorflow -y \
     tensorflow numpy scipy pandas scikit-learn
        </programlisting>
        <para>In case your machine has GPU hardware for tensorflow, replace
        <quote>tensorflow</quote> by <quote>tensorflow-gpu</quote>.</para>
        <note>Note that on systems with typical core i7 architecture 
        recompiling tensorflow from source provided only very small runtime
        gains in our tests which in most cases do not support the extra effort.
        You may find it necessary for tackling really large networks and 
        datasets and especially if you desire using Intel's MKL library for the
        CPU-based linear algebra computations.</note>
        <para>Henceforth, we assume that there is a working tensorflow on 
        your system, i.e. inside the python3 shell</para>
        <programlisting>import tensorflow as tf</programlisting>
        <para>does <emphasis>not</emphasis> throw an error.</para>
        <para>Moreover,</para>
        <programlisting>a=tf.constant("Hello world")
sess=tf.Session()
sess.run(a)</programlisting>
        <para>should print <quote>Hello world</quote> or something similar.
        </para>
      </section>
      <section xml:id="introduction.installation.procedure">
        <title xml:id="introduction.installation.procedure.title">Installation procedure</title>
        <para>This package is distributed via autotools, "compiled" and installed 
        via automake. If you are familiar with this set of tools, there should be
        no problem. If not, please refer to the text INSTALL file that is included
        in this distributable archive. The installation, very briefly, is 
        accomplished like this:</para>
        <programlisting>
./bootstrap.sh
mkdir build64
cd build64
../configure --prefix="somepath" -C PYTHON="path to python3"
make
make install
        </programlisting>
        <para>where the first step is only required if you have obtained the 
        package through cloning the github repository. If you extracted it from
        a distributable tarball, then it is not necssary.</para>
        <para>Here, "compilation" is done in an extra folder 
        <quote>build64</quote>, i.e. it is an out-of-source build, that 
        prevents cluttering of the source folder. Naturally, you may pick any
        name (and actually any location on your computer) as you see fit.
        </para>
        <para>More importantly, please replace <quote>somepath</quote> and 
        <quote>path to python3 </quote> by the desired installation path and 
        the full path to the <command>python3</command> executable on your 
        system.</para>
        <note>In case of having used <productname>anaconda</productname>
        for the installation of required packages, then you need to look in
        <programlisting>$HOME/.conda/envs/tensorflow/bin/python3</programlisting>
        for the respective command, where <quote>$HOME</quote> is your home
        folder. This assumes that your anaconda environment is named
        <quote>tensorflow</quote> as in the example installation steps above.
        </note>
        <note>We recommend executing (after <quote>make install</quote> was run)
          <programlisting>make check</programlisting>
          additionally. This will execute every test on the extensive testsuite
          and report any errors. None should fail. If all fail, a possible cause 
          might be a not working tensorflow installation. If some fail, please
          contact the author, see <xref linkend="introduction.feedback"/>.
          As always with GNU make you may use <command>make -j4 check</command>
          to execute four processes in parallel performing the checks which
          should give a significant speed up. Replace "4" by the number of
          cores in your machine or any other number you find appropriate.
        </note>
      </section>
    </section>
    <section xml:id="introduction.license">
      <title xml:id="introduction.license.title">License</title>
      <para>As long as no other license statement is given, ThermodynamicAnalyticsToolkit is
      free for use under the GNU Public License (GPL) Version 3 (see
      <uri>www.gnu.de/documents/gpl-3.0.de.html</uri>).</para>
    </section>
    <section xml:id="introduction.disclaimer">
      <title xml:id="introduction.disclaimer.title">Disclaimer</title>
      <para>We quote section 11 from the GPLv3 license:</para>
      <remark>Because the program is licensed free of charge, there is
not warranty for the program, to the extent permitted by applicable law.
Except when otherwise stated in writing in the copyright holders and/or
other parties provide the program &quot;as is&quot; without warranty of
any kind, either expressed or implied. Including, but not limited to,
the implied warranties of merchantability and fitness for a particular
purpose. The entire risk as to the quality and performance of the
program is with you. Should the program prove defective, you assume the
cost of all necessary servicing, repair, or correction.</remark>
    </section>
    <section xml:id="introduction.feedback">
      <title xml:id="introduction.feedback.title">Feedback</title>
      <para>If you encounter any bugs, errors, or would like to submit
      feature request, please use the email address provided at the very
      beginning of this user guide. The author is especially thankful for
      any description of all related events prior to occurrence of the
      error and auxiliary files.
      Please mind sensible space restrictions of email attachments.</para>
    </section>
  </chapter>
  
  <chapter xml.id="quickstart">
    <title  xml.id="quickstart.title">Quickstart</title>
    <section xml.id="quickstart.introduction">
      <title  xml.id="quickstart.introduction.title">Sampling in neural networks</title>
      <para>Assume we are given a very simple data set as depicted in 
      <xref xrefstyle="template:Figure %n" linkend="quickstart.introduction.dataset"/>. 
      <figure xml:id="quickstart.introduction.dataset">
        <title>Dataset: two gaussian distributed point clouds</title>
        <mediaobject>
          <imageobject>
            <imagedata width="30%" scalefit="1." entityref="dataset_two_clusters"/>
          </imageobject>
        </mediaobject>
      </figure>
      The goal is to classify all red and blue dots into two different classes. This
      problem  is quite simple to solve: a line in the two-dimensional space can 
      easily separate the two classes.</para>
      <para>A very simple neural network, a perceptron, is all we need:  it uses 
      two inputs nodes, namely each coordinate component, 
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
            <mml:msub>
              <mml:mi>x</mml:mi>
              <mml:mn>1</mml:mn>
            </mml:msub>
          </mml:mrow>
        </mml:math>
      </inlineequation>
      and
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
            <mml:msub>
              <mml:mi>x</mml:mi>
              <mml:mn>2</mml:mn>
            </mml:msub>
          </mml:mrow>
        </mml:math>
      </inlineequation>,
      and a single output 
      node with an activation function
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
              <mml:mi>f</mml:mi>
          </mml:mrow>
        </mml:math>
      </inlineequation>
      whose sign gives the class the input item belongs to. The network is 
      given in 
      <xref xrefstyle="template:Figure %n" linkend="quickstart.introduction.perceptron"/>.
      </para>
    <figure xml:id="quickstart.introduction.perceptron">
        <title>Simple single-layer perceptron with weights and biases</title>
        <mediaobject>
          <imageobject>
            <imagedata width="30%" scalefit="1." entityref="simple_single_layer_perceptron"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>In the following we want to use the mean square loss, i.e. the 
      euclidian distance between the output from the network and the expected
      values per item, as the network's loss function. The loss depends 
      implicitly on the dataset and explicitly on the weights and biases 
      associated with the network. In our case, we have two weights for the two
      edges between input nodes, 
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
            <mml:msub>
              <mml:mi>w</mml:mi>
              <mml:mn>1</mml:mn>
            </mml:msub>
          </mml:mrow>
        </mml:math>
      </inlineequation>
      and
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
            <mml:msub>
              <mml:mi>w</mml:mi>
              <mml:mn>2</mml:mn>
            </mml:msub>
          </mml:mrow>
        </mml:math>
      </inlineequation>,
      and the output node and a single bias attached
      to the output node
      <inlineequation>
        <mml:math display="inline">
          <mml:mrow>
              <mml:mi>b</mml:mi>
          </mml:mrow>
        </mml:math>
      </inlineequation>.
      </para>
      <para>In sampling we look at a system of particles that have two internal
      properties: location and momentum. The location is simply their current 
      value, that changes through its momentum over time. The momentum again 
      changes because the particle is inside a potential that drives it towards
      the minimum. The system is described by a so-called Hamilton operator
      that gives rise to its same named dynamics. If noise is additionally taken into 
      account, then we look at Langevin Dynamics.</para>
      <para>Returning to the neural networks, the role of the particles is taken
      by the degrees of freedom of the system: weights and biases. The loss
      function is called the <emphasis>potential</emphasis> and it is accompanied 
      by a <emphasis>kinetic energy</emphasis> that is simply the sum of all
      squared momenta. Adding Momentum to Optimizers in neural networks is a
      concept known already and inspired by physics. The momentum helps in
      overcoming areas of the loss function where it is essentially flat.</para>
      <para>Sampling produces trajectories of particles moving along the
      manifold. Integrals along these trajectories, if they are long enough, 
      are equivalent to integrating over the whole manifold, if the system is
      ergodic.</para>
      <para>By using sampling we mean to discover more of the loss manifold
      than just the closest local minimum. The wording seems to indicate that 
      we would like to explore <emphasis>all</emphasis> of the loss manifold. 
      However, this is not the case as there are regions we are not interested
      in, namely those with large loss function values. In other words, we
      would like to sample in such a way as only to stay in regions of the loss
      manifold associated with small values. Generating trajectories by 
      dynamics where the negative of the gradient acts as a driving force onto
      each particle automatically brings them into regions where the
      loss's value is small. This is the principle behind Gradient Descent.
       However, in general all possible minima locations will not form a
       connected region on the loss manifold. These minima regions may
       be separated by barriers which are needed to overcome. We distinguish
       two kinds,</para>
      <itemizedlist>
        <listitem>entropic barriers,</listitem>
        <listitem>enthalpic barriers.</listitem>
      </itemizedlist>
      <para>Both of which are conceptually very simple. The enthalpic barrier
      is simply a ridge that is very high where the particles need a large 
      momentum to overcome it. Entropic barriers on the other hand are passages
      very small in volume that are simply very difficult to find. In order to
      overcome barriers of the first kind, higher temperatures suffice.
      For the second type of barrer, this is not so easy. Metaphorically
      speaking, we are looking for possibly very small door.</para>
      <para>This quick description of the problem of sampling in the context
      of neural networks in data science should have prepare you now for the
      following quickstart tutorial on how to actually use ThermodynamicAnalyticsToolkit 
      to perform sampling.</para>
      <para>Let us have a closer look at a very simple loss landscape. In
      <xref linkend="quickstart.introduction.landscape.neuralnetwork">Figure</xref>
      we look at a very simple network of a single input node, with a single 
      hidden layer containing just one node and a single output layer. 
      Activation function is linear everywhere. We set the output node's and 
      hidden node's bias to zero. The dataset contains two cluster of points,
      one (label -1) centered at -2, another (label +1) centered at 2 which we 
      do not depict here. Any product of the two degrees of freedom of the 
      network, namely its two weights, equal to unity will classify the data 
      well.</para>
    <figure xml:id="quickstart.introduction.landscape.neuralnetwork">
        <title>Neural network with permutation symmetry to provoke multiple minima</title>
        <mediaobject>
          <imageobject>
            <imagedata width="45%" scalefit="1." entityref="neuralnetwork_permutation_symmetry"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>In <xref linkend="quickstart.introduction.landscape.loss">Figure</xref>
      we then turn to the loss landscape depending on either weight. We see
      two minima basins both of hyperbole or "banane" shape. There is a clear
      (enthalpic) potential barrier in between. However, the minima basins
      themselves are to some part entropic barriers as they are elongated and 
      flat.</para>
      <para>In the figure we also give a trajectory. Here, we have chosen such
      a (inverse) temperature value such that it is able to pass the potential
      barrier and reach the other minima basin.</para>
    <figure xml:id="quickstart.introduction.landscape.loss">
        <title>Loss landscape with an example trajectory</title>
        <mediaobject>
          <imageobject>
            <imagedata width="45%" scalefit="1." entityref="losslandscape_permutation_symmetry"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>This is the goal of exploration: To find all (local) minima to allow
      to pick the lowest, namely the global minimum.</para>
    </section>
    <section xml:id="quickstart.python">
      <title  xml:id="quickstart.python.title">Using Python</title>
      <para>
      The package can be readily used inside any python3 shell or script.
      However, this interface rather lends itself to quick testing than rigorous
      experiments. You are still fine if you perform all your scientific 
      experiments inside python scripts kept safely inside a code versioning 
      system such as <command>git</command>.</para>
      <para>
      If you have installed the package in the folder "/foo", i.e. we have 
      folders "ThermodynamicAnalyticsToolkit/models" with a file 
      <command>model.py</command> residing in there, then you 
      probably need to add it to the 
      <command>PYTHONPATH</command> as follows</para>
      <programlisting>PYTHONPATH=/foo python3</programlisting>
      <para>In this shell, you may import the sampling part of the package as 
      follows 
      <programlisting>from TATi.models.model import model</programlisting>
      This will import the abstract <command>model</command> class from the
      file mentioned before. This class contains wrapper functions to setup 
      the network with either training and sampling in a few keystrokes.</para>
      <para>In order to make you own python scripts executable and know about
      the correct (non-standard) path to ThermodynamicAnalyticsToolkit, place the following
      two lines at the veryg beginning of your script:</para>
      <programlisting>import sys
sys.path.insert(1,"&lt;path_to_TATi&gt;/lib/python3.5/site-packages/")</programlisting>
      <para>where <quote>&lt;path_to_TATi&gt;</quote> needs to be replaced by your
      specific installation path.</para>
      
      <section xml:id="quickstart.python.simple_evaluation">
        <title  xml:id="quickstart.python.simple_evaluation.title">Evaluating loss and gradients</title>
        <para>ThermodynamicAnalyticsToolkit can also be used as a simplified interface to
        access the loss and the gradients of the neural network. Then, it can be
        treated as a simple high-dimensional function (the loss), whose 
        derivative (the gradients) is available as a numpy array. See the 
        following example which sets up a simple fully-connected hidden
        network and evaluates loss and then loss and gradients combined.
        <example xml:id="quickstart.python.simple_evaluation.example">
          <title>Evaluating loss and gradients through the Python API</title>
          <programlisting><xi:include  href="python/eval_loss_gradient.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        </para>
      </section>  
      
      <section xml:id="quickstart.python.writing_data">
        <title  xml:id="quickstart.python.writing_data.title">Preparing a dataset</title>
        <para>At the moment, datasets are parsed from Comma Separated Values 
        (CSV) files.  In order for the following examples on optimization and 
        sampling to work, we need such a data file containing features and labels.</para>
        <para>One option is to use the TATiDatasetWriter, see 
        <xref linkend="quickstart.cmdline.writing_dataset"/>. However, we can
        do the same using python as well.</para>
        <example xml:id="quickstart.python.writing_data.example">
          <title>Writing the "two clusters" dataset to a CSV file</title>
          <programlisting><xi:include  href="python/writing_data.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>After importing some modules we first fix the 
        numpy seed to 426 in order to get the same items reproducibly.
        Then, we first create 100 items using the hard-coded
        ClassificationDatasets class from the <quote>TWOCLUSTERS</quote> 
        dataset. We randomly perturb by a relative noise of 0.1.</para>
        <para>Afterwards, these items are simply written to file using the csv
        module.</para>
        <note>The file <quote>dataset-twoclusters.csv</quote> is used in 
        the following examples, so keep it around.</note>
      </section>
      
      <section xml:id="quickstart.python.optimizing">
        <title  xml:id="quickstart.python.optimizing.title">Optimizing the network</title>
        <para>Let us first start with optimizing the network.</para>
        <example xml:id="quickstart.python.optimizing.example">
          <title>Optimizing network for two clusters dataset</title>
          <programlisting><xi:include  href="python/optimize.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>
        As you see, all options are set in a struct called <command>FLAGS</command> 
        that controls how the optimization is performed. 
        There is a helper function in <command>model</command> called 
        <command>setup_parameters</command>
        that creates the FLAGS for you with some default parameters. </para>
        <para>Let us quickly go through each of the parameters: 
        <itemizedlist>
          <listitem>
          <emphasis>batch_size</emphasis> sets the subset size of the data set
          looked at per training step, if smaller than dimension, then we add
          stochasticity/noise to the training but for the advantage of smaller
          runtime.
          </listitem><listitem>
          <emphasis>max_steps</emphasis> gives the amount of training steps to
          be performed.
          </listitem><listitem>
          <emphasis>optimizer</emphasis> defines the method to use for training.
          Here, we use Gradient Descent (in case batch_size is smaller than 
          dimension, then we actually have Stochastic Gradient Descent).
          </listitem><listitem>
          <emphasis>output_activation</emphasis> defines the activation function
          of all output nodes, here it is linear. Other choices are: tanh, relu, relu6.
          </listitem><listitem>
          <emphasis>seed</emphasis> sets the seed of the random number generator.
          We will still have full randomness but in a deterministic manner, i.e. 
          calling the same procedure again will bring up the exactly same values.
          </listitem><listitem>
          <emphasis>step_width</emphasis> defines the scaling of the gradients
          in each training step, i.e. the learning rate. Values too large may miss the
          minimum, values too small need longer to reach it.
          </listitem>
        </itemizedlist>
        </para>
        <para>For small networks the option <quote>do_hessians</quote>
        might be useful which will compute the hessian matrix at the end of the
        trajectory and use the largest eigenvalue to compute the optimal step
        width. This will add nodes to the underlying computational graph for
        computing the components of the hessian matrix. <note>The creation of 
        the nodes (not speaking of their evaluation) is a O(N^2) process in 
        the number of parameters of the network N. Hence, this should only be 
        done for small networks and on purpose.</note></para>
        <para>Moreover, we did not say anything about <emphasis>sampler</emphasis>
         as this is covered in the next section.</para>
        <para>Afterwards, the network is initialized, then we call <command>train()</command>
        which performs the training and returns runtime info, trajectory, and 
        averages as a pandas DataFrame.</para>
        <para>At the end of this section on training, let us have a quick 
        glance at the decrease of the loss function over the steps by using
        <command>matplotlib</command>.</para>
        <example xml:id="quickstart.python.optimizing.example2">
          <title>Plotting the loss and other properties over steps</title>
          <programlisting><xi:include  href="python/plot_optimize.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>The graph should look similar to the one obtained with 
        pgfplots (see <uri>https://sourceforge.net/pgfplots</uri> in 
        <xref linkend="quickstart.python.optimizing.plot">Figure</xref>.
        </para>
        <figure xml:id="quickstart.python.optimizing.plot">
            <title>Plot of the loss history for the optimization run</title>
            <mediaobject>
              <imageobject>
                <imagedata width="50%" scalefit="1." entityref="optimization_step_loss"/>
              </imageobject>
            </mediaobject>
          </figure>
          <para>Go and have a look at the other columns. Or try to visualize the 
          change in the parameters (weights and biases) in the trajectories
          dataframe.</para>
      </section>
      <section xml:id="quickstart.python.sampling">
        <title  xml:id="quickstart.python.sampling.title">Sampling the network</title>
        <para>After optimization we may continue sampling the network.</para>
        <example xml:id="quickstart.python.sampling.example">
          <title>Sampling the loss manifold using GLA 2nd</title>
          <programlisting><xi:include  href="python/sample.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>Here, the <emphasis>sampler</emphasis> setting takes the place
        of the <command>optimizer</command> before as it states which sampling 
        scheme to use. At the moment the following are available: 
        <firstterm linkend="SGLD">SGLD</firstterm> 
        <firstterm linkend="GLA">GeometricLangevinAlgorithm_1st</firstterm>, 
        <firstterm linkend="GLA">GeometricLangevinAlgorithm_2nd</firstterm>, BAOAB,
        and <firstterm linkend="HMC">HamiltonianMonteCarlo</firstterm>. GLA 2nd or 
        BAOAB are currently recommended to use as they are second order schemes
        and provide higher accuracies and allow for larger step widths.</para>
        <para>Again, we produce three output arrays: run info, trajectory, and
        averages. Trajectories contains among others all parameter degrees of
        freedom for each step (or <quote>every_nth</quote> step). Run info
        contains loss, accuracy, norm of gradient, norm of noise and others.
        Finally, in averages we compute averages over the trajectory such as
        average (ensemble) loss, average kinetic energy, average virial. There 
        it is advisable to skip some initial ateps (<quote>burn_in_steps</quote>)
        to allow for some burn in time, i.e. for kinetic energies to adjust 
        from initially zero momenta. Some columns depend on whether the 
        sampler provides the specific quantity, e.g. SGLD does not have 
        momentum, hence there will be no average kinetic energy.</para>
        <section xml:id="quickstart.python.sampling.supply_dataset">
          <title  xml:id="quickstart.python.sampling.supply_dataset.title">Provide your own dataset</title>
          <para>Using the Python API you can directly supply your own dataset, 
        e.g. from a numpy array residing in memory. See the following example 
        where we do not generate the data but parse them from a CSV file
        instead using the pandas module.</para>
          <example xml:id="quickstart.python.supply_dataset.example">
            <title>Supplying a dataset in the form of a numpy array (parsed from a CSV file)</title>
            <programlisting><xi:include  href="python/supply_dataset.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          </example>
          <para>The major difference is that <command>batch_data_files</command>
          is now empty and instead we call the function <command>provide_data</command>
          in order to provide an in-memory dataset. In this example, we have 
          parsed the same file as the in the previous section into a numpy 
          array using the pandas module. Natually, this is just one way of
          creating a suitable numpy array. Input and output dimensions are
          directly deduced from the the tuple sizes.</para>
          <para>Note that we have ignored the average output here, by default
          none of the three output pandas dataframes are accumulated.</para>
        </section>
        <section xml:id="quickstart.python.sampling.priors">
          <title  xml:id="quickstart.python.sampling.priors.title">Using a prior</title>
          <para>You may add a prior to the sampling. At the current state two 
          kinds of priors as follows are available. In <quote>FLAGS</quote>
          <command>prior_upper_boundary</command> and 
          <command>prior_lower_boundary</command> give the admitted interval
          per parameter. Within a relative distance of 0.01 (with respect to 
          length of domain and only in that small region to the specified 
          boundary) an additional force acts upon the particles to drive them
          back into the desired domain. Its magnitude increases with distance 
          to the covered inside the boundary region. The distance is taken to
          the power of <command>prior_power</command>. The force is modified 
          by <command>prior_factor</command>.</para>
          <para>If upper and lower boundary coincide, then we have the case
          of tethering, where all parameters are pulled inward to the same 
          point.</para>
          <para>At the moment prioring just a subset of particles is not
          supported.</para>
          <note>The prior force is acting directly on the variables. It does not 
          modify momentum. Moeover, it is a force! In other words, it depends on
          step width. If the step width is too large and if the repelling force
          increases too steeply close to the walls with respect to the normal
          dynamics of the system, it may blow up.
          </note>
        </section>
        <section xml:id="quickstart.python.sampling.optimize_then_sample">
          <title  xml:id="quickstart.python.sampling.optimize_then_sample.title">First optimize, then sample</title>
          <para>We might also concatenate optimize and sample if, in between the
          two, we adjust FLAGS as follows:
          <example xml:id="quickstart.python.sampling.example.combined">
            <title>Optimizing first and subsequent sampling</title>
            <programlisting><xi:include  href="python/optimize_sample.py"  parse="text"  
        xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          </example>
          The only thing we change in FLAGS is the number of steps and adding the
          sampler. However, as the model simply stores a copy of the FLAGS, in 
          order to update the FLAGS in the model class as well, we need to reset 
          it. Afterwards, we again  initialize the network which will add only the 
          sampling nodes and prepare output files differently.
          We have skipped the following steps that are equivalent to
          <xref xrefstyle="template:Example %n" linkend="quickstart.python.sampling.example"/>.
          Again, at the very end we obtain pandas DataFrame containing runtime 
          information, trajectory, and averages.
          <note>This is actually the <emphasis>recommended</emphasis> way of
          doing sampling: First make sure that the parameters start in a local 
          minima and from there we explore the surrounding manifold.</note>
          </para>
        </section>
      </section>
      <section xml:id="quickstart.python.analysis">
        <title  xml:id="quickstart.python.analysis.title">Analysing trajectories</title>
        <para>Analysis is so for constrained to parsing in run and trajectory
        files that you would write through optimization and sampling runs.</para>
        <para>To this end, specify <command>FLAGS.run_file</command> and
        <command>FLAGS.trajectory_file</command> with some valid file names.</para>
        <para>Subsequently, these may be easily parsed as follows, see also
         "TATiAnalyser.in".</para>
        <example xml:id="quickstart.python.analysis.example">
          <title>Plotting the averages of the parameters over steps</title>
          <programlisting><xi:include  href="python/analyse.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>This would give a plot of the running average for each parameter
        in the trajectory file. In a similar, the run file can be loaded and its
        average quantities such as loss or kinetic energy be analysed and 
        plotted.</para>
      </section>
      <section xml:id="quickstart.python.exploration">
        <title  xml:id="quickstart.python.exploration.title">Exploring the loss manifold</title>
        <para>Exploration of the loss manifold is a bit more involved using
        the python interface.</para>
        <para>In general, the procedure has the following stages:</para>
        <itemizedlist>
          <listitem><para>We sample a start trajectory.</para></listitem>
          <listitem><para>For the current set of trajectory points we perform a
          diffusion map analysis. Using the first eigenvector as the dominant
          diffusion mode, we pick the first corner points at its maximal
          component.</para></listitem>
          <listitem><para>If more corner points are needed, then we look at
          the diffusion distance with respect to already picked corner points
          over all eigenvectors of the diffusion map and pick the next point
          always such that it maximizes the diffusion distance to the present
          ones.</para></listitem>
          <listitem><para>Finally, we sample further trajectories, one starting
          at each of the picked corner points.</para></listitem>
          <listitem><para>This is repeated (go to second step) for as many
          exploration steps as we want to do.</para></listitem>
        </itemizedlist>
        <para>Note that each single trajectory is sampled in a special way:</para>
        <itemizedlist>
          <listitem><para>First, three legs of sampling are performed</para></listitem>
          <listitem><para>Then, we analyse the resulting diffusion map.</para></listitem>
          <listitem><para>If the eigenvalues have not yet converged with respect
          to some relative threshold, we continue for one more leg and analyse
          again after that</para></listitem>
          <listitem><para>If they have converged, we stop.</para></listitem>
          <listitem><para>Finally, we look at the norm of the gradients along
          the trajectory. If it is below a certain threshold, then within this
          section of the trajectory (with gradient norms beneath the threshold)
          we pick the smallest gradient value as the trajectory step being a
          possible minimum candidate.</para></listitem>
          <listitem><para>For all minimum candidates (if any) we run additional
          optimization trajectories, e.g. using GradientDescent, to find a local
          minima.</para></listitem>
        </itemizedlist>
        <para>Have a look at the following example.</para>
        <example xml:id="quickstart.python.exploration.example">
          <title>Exploring the loss manifold using multiple trajectories from 
          corner points in the diffusion map</title>
          <programlisting><xi:include  href="python/explore.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>This performs exactly the procedure described before using
        very, very short trajectories (<command>max_steps</command>),
        only a few legs (<command>max_legs</command>) and only a
        very limited number of exploration steps (<command>exploration_steps
        </command>). This is simple for the purpose of illustration. Naturally,
        larger values for all these parameters are required in order to explore
        complex manifolds and eventually find the global minima.</para>
        </section>
    </section>
    <section xml:id="quickstart.cmdline">
      <title  xml:id="quickstart.cmdline.title">Using command-line interface</title>
      All the tests use the command-line interface and for performing rigorous
      scientific experiments, we recommend using this interface as well. Here,
      it is to do parameter studies and have extensive runs using different
      seeds.
      <section xml:id="quickstart.cmdline.writing_dataset">
        <title  xml:id="quickstart.cmdline.writing_dataset.title">Creating the dataset</title>
        <para>As data is read from file, this file needs to be created beforehand.</para>
        <para>For a certain set of simple classification problems, namely those 
        that can be found in the tensorflow playground, we have added a
        <quote>TATiDatasetWriter</quote> that spills out the dataset in CSV format.
        </para>
        <example xml:id="quickstart.cmdline.writing_dataset.example">
          <title>Creating the "two clusters" dataset as CSV file</title>
          <programlisting><xi:include  href="cmdline/write_dataset.sh"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>This will write 500 datums of the dataset type 2 ("two clusters")
        to a file <quote>testset-twoclusters.csv</quote> using all of the points as we have
        set the test/train ratio to 0. Note that we also perturb the points by
        0.1 relative noise.</para>
      </section>
      <section xml:id="quickstart.cmdline.parsing_dataset">
        <title  xml:id="quickstart.cmdline.parsing_dataset.title">Parsing the dataset</title>
        <para>Similarly, for testing the dataset can be parsed using the same
        tensorflow machinery as is done for sampling and optimizing, using</para>
        <example xml:id="quickstart.cmdline.parsing_dataset.example">
          <title>Parsing dataset from CSV file</title>
          <programlisting><xi:include  href="cmdline/parse_dataset.sh"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>where the <emphasis>seed</emphasis> is used for shuffling the
        dataset.</para>
      </section>
      <section xml:id="quickstart.cmdline.optimizing">
        <title  xml:id="quickstart.cmdline.optimizing.title">Optimizing the network</title>
        <para>As weights (and biases) are usually uniformly random initialized and
        the potential may therefore start with large values, we first have to 
        optimize the network, using (Stochastic) Gradient Descent (GD).</para>
        <example xml:id="quickstart.cmdline.optimizing.example">
          <title>Optimizing the network with Gradient Descent on Two Clusters dataset</title>
          <programlisting><xi:include  href="cmdline/optimize.sh"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>This call will parse the dataset from the file
         "dataset-twoclusters.csv".  It will then perform a (Stochastic) 
         Gradient  Descent optimization in batches of 50 (10% of the dataset) 
         of the parameters of the network using a step width/learning rate of 
         0.01 and do this for 1000 steps after which it stops and writes the 
         resulting neural network in a TensorFlow-specific format to a set of 
         files, one of which is called <command>model.ckpt.meta</command> (and 
         the other filenames are derived from this).</para>
        <para>We have also created a file <filename>run.csv</filename> which
        contains among others the loss at each (<quote>every_nth</quote>, 
        respectively) step of the optimization run. Plotting the loss over the 
        step column from the run file will result in a figure similar to in 
        <xref linkend="quickstart.python.optimizing.plot"/>.</para>
        <note>Since Tensorflow 1.4 an absolute path is required for the storing 
        the model. In the example we use the current directory returned by the
        unix command <command>pwd</command>.</note>
        <para>If you need to compute the optimal step width, which is possible
        for smaller networks from the largest eigenvalue of the hessian matrix,
        then use the option <quote>do_hessians 1</quote> to activate it.
        <note>The creation of the nodes is costly, O(N^2) in 
        the number of parameters of the network N. Hence, may not work for
        anything but small networks and should be done on purpose.</note></para>
        <para>In case you have read the quickstart tutorial on the Python
        interface before, then the names of the command-line option will
        probably remind you of the variables in the FLAGS structure.</para>
      </section>  
      <section xml:id="quickstart.cmdline.sampling">
        <title  xml:id="quickstart.cmdline.sampling.title">Sampling trajectories on the loss manifold</title>
        <para>We continue from this optimized or equilibrated state with sampling.
        It is called equilibrated as the network's parameter should now be close to
        a (local) minimum of the potential function and hence in equilibrium. This
        means that small changes to the parameters will result in gradients that 
        force it back into the minimum.</para>
        <para>Let us call the sampler.</para>
        <example xml:id="quickstart.cmdline.sampling.example">
          <title>Sampling the loss manifold using on Two Clusters dataset</title>
          <programlisting><xi:include  href="cmdline/sample.sh"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
        <para>This will cause the sampler to parse the same dataset as before.
        Moreover, the sampler will load the neural network from the model, i.e.
        using the optimized parameters right from the start.
        Afterwards it will use the <glossterm linkend="GLA">GLA</glossterm> 
        in 2nd order discetization using again step_width of 0.01 and running 
        for 1000 steps in total. The <glossterm linkend="GLA">GLA</glossterm> 
        is a descretized variant of Langevin Dynamics whose accuracy scales 
        with the inverse square of the step_width (hence, 2nd order).</para>
        <para>The seed is needed as we sample using Langevin Dynamics where
        a noise term is present. The term basically ascertains a specific 
        temperature which is proportional to the average momentum of each 
        particle.</para>
        <para>After it has finished, it will create three files; a run file 
        <filename>run.csv</filename>containing run time information such as the 
        step, the potential, kinetic and total energy at each step, a 
        trajectory file <filename>trajectory.csv</filename>with each parameter 
        of the neural network at each step, and an averages file 
        <filename>averages.csv</filename> containing averages accumulated along
        the trajectory such as average kinetic energy, average virial (
        connected to the kinetic energy through the virial theorem, valid if a
        prior keeps parameters bound to finite values), and the average
        (ensemble) loss. Moreover, for the <glossterm linkend="HMC">HMC</glossterm>
        sampler the average rejection rate is stored there. 
        The first two files we need in the next stage.</para>
      </section>
      <section xml:id="quickstart.cmdline.analysing">
        <title  xml:id="quickstart.cmdline.analysing.title">Analysing trajectories</title>
        <para>Eventually, we now perform the diffusion map analysis on the obtained
        trajectories. The trajectory file written in the last step is simply a matrix
        of dimension (number of parameters) times (number of trajectory steps).
        The eigenvector to the largest (but one) eigenvalue will give the dominant 
        direction in which the trajectory is moving.</para>
        <note>The largest eigenvalue is usually unity and its eigenvector is 
        constant.</note>
        <para>The analysis can perform three different tasks:</para>
        <itemizedlist>
          <listitem>Calculating averages.</listitem>
          <listitem>Calculating the diffusion map's largest  eigenvalues and 
          eigenvectors.</listitem>
          <listitem>Calculating landmarks and level sets to obtain an approximation
          to the free energy.</listitem>
        </itemizedlist>
        <section xml:id="quickstart.cmdline.analysing.averages">
          <title  xml:id="quickstart.cmdline.analysing.averages.title">Averages</title>
          <para>Averages are calculated by specifying two options as follows:</para>
          <example xml:id="quickstart.cmdline.analysing.averages.example">
            <title>Calculating averages over a sampled trajectory</title>
            <programlisting><xi:include  href="cmdline/analyse_average.sh"  parse="text"  
        xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          </example>
          <para>This will load both the run file <command>run.csv</command>
          and the trajectory file <command>trajectory.csv</command>and average
           over them using only every 10th data point 
           (<emphasis>every_nth</emphasis>) and also dropping the first steps 
           below 100 (<emphasis>drop_burnin</emphasis>). It will produce then
           ten averages (<emphasis>steps</emphasis>) for each of energies in the 
           run file and each of the parameters in the trajectories file (along 
           with the variance) from the first non-dropped step till one of the 
           ten end steps. These end steps are obtained by equidistantly 
           splitting up the whole step interval.</para>
           <para>Eventually, we have two output file. The averages over the run
           information such as total, kinetic, and potential energy in
           <command>average_run.csv</command>. Also, we have the averages
           over the degrees of freedom in 
           <command>average_trajectories.csv</command>.</para>
           <note>Averages depend crucially on the number of steps we average
           over. I.e. the more points we throw away, the less accurate it 
           becomes. In other words, if large accuracy is required, the averages
           file (if it contains the value of interest) is a better place to 
           look for.</note>
        </section>
        <section  xml:id="quickstart.cmdline.analysing.diffusion_map">
          <title  xml:id="quickstart.cmdline.analysing.diffusion_map.title">Diffusion map</title>
          <para>The eigenvalues and eigenvectors can be written as well to two 
          output files.</para>
          <example xml:id="quickstart.cmdline.analysing.diffusion_map.example">
            <title>Calculating diffusion maps on a sampled trajectory</title>
            <programlisting><xi:include  href="cmdline/analyse_diffmap.sh"  parse="text"  
        xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          </example>
          <para>The files ending in <command>..values.csv</command> contains 
          the eigenvalues in two columns, the first is the eigenvalue index,
          the second is the eigenvalue.</para>
          <para>The other file ending in <command>..vectors.csv</command> is 
          simply a matrix of the eigenvector components in one direction and 
          the trajectory steps in the other. Additionally, it contains the 
          parameters at the steps and also the loss and the kernel matrix 
          entry.</para>
          <para>Note that again the all values up till step 100 are dropped 
          and only every 10th trajectory point is considered afterwards.</para>
          <para>There are two methods available. Here, we have used the
          simpler (and less accurate) (plain old) vanilla method. The other is
          called TMDMap.</para>
          <para>If you have installed the <emphasis>pydiffmap</emphasis>
          python package, this mal also be specified as diffusion map method.
          It has the benefit of an interal optimal parameter choice. Hence, it
          should behave more robustly than the other two methods.
          TMDMap is different only in reweighting tre samples according to
          the specific temperature.</para>
        </section>
        <section xml:id="quickstart.cmdline.analysing.free_energy">
          <title  xml:id="quickstart.cmdline.analysing.free_energy.title">Free energy</title>
          <para>Last but not least, the free energy is calculated.</para>
          <example xml:id="quickstart.cmdline.analysing.free_energy.example">
            <title>Calculating free energy over profiles  over diffusion map eigenvectors on a sampled trajectory</title>
            <programlisting><xi:include  href="cmdline/analyse_free_energy.sh"  parse="text"  
        xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          </example>
          <para>This will extract landmark points from the trajectory. 
          Basically, the loss manifold is discretized using these landmarks
          where all configurations close to a landmark step are combined
          onto a so-called level-set, i.e. all these configurations have a
          similar loss function value. By knowing the number of configurations
          in each level set and knowing the level sets loss value, an 
          approximation of the free energy is computed.</para>
          <para>This is computed for every step of the trajectory and it is
          insightful to look at the free energy over the course of the
          trajectory represented by the first eigenvalue. If in this graph
          clear minima with maxima in between can be seen, then there
          are enthalpic barriers between two local minima. If on the other
          hand there are flat areas, then we found entropic barriers.</para>
          <para>Both these types of barriers obstruct trajectories and keep
          the optimization trapped in so-called meta-stable states. Each type
          of barrier requires a different type of remedy to overcome.</para>
        </section>
      <section xml:id="quickstart.cmdline.exploration">
        <title  xml:id="quickstart.cmdline.exploration.title">Exploring the loss manifold</title>
        <para>Eventually, we are not interested in obtaining trajectories on the
        loss manifold. Instead we would like to find the global minima. Or at 
        least have a good idea about whether the minimas we have found so far 
        are reasonable.</para>
        <para>To this end, a command-line tool called 
        <command>TATiExplorer</command> is provided. The idea is to make use
        of the diffusion map with its diffusion distance to assess what part of 
        the loss manifold has been explored already. Moreover, we use multiple
        trajectories that are spawned from a specific number of places that are
        maximally separate with respect to their diffusion distance. This will
        ensure that we cover the most ground possible.</para>
        <para>In the end, the eigenvectors obtained through a run using the
        <command>TATiExplorer</command> will return the dominant diffusion
        directions and therefore those pointing in the direction along the 
        minima, i.e. where the sampling usually gets stuck and remains for
        a while, hence diffusion is slow.</para>
        <example xml:id="quickstart.cmdline.exploration.example">
          <title>Exploring the loss manifold</title>
          <programlisting><xi:include  href="cmdline/exploring.sh"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
          <programlisting>
          </programlisting>
          <para>In the example we call the explorer utility in much the same 
          way as we have called the sampler. There are some additional options
          that give the number of eigenvalues to calculate and which diffusion
          map method to use. Note that <command>max_steps</command>
          now gives the number of steps of a single leg. Further down you find
          what a lag actually is.</para>
          <para>Furthermore, there are two options unique to the explorer.
          This is <command>max_legs</command> which gives the maximum number
          of legs to look at. Each leg goes over max_steps. After that a 
          diffusion map analysis is performed that checks whether the 
          eigenvalues have converged already. If yes, the trajectory is ended,
          if not we continue with a new leg (of max_steps steps). If no 
          convergence should occur, max_legs gives the maximum number of legs
          after which the trajectory is terminated regardlessly.</para>
          <para>Finally, we run multiple trajectories in parallel from
          starting points that are maximally apart from each other in the
          sense of the diffusion distances. This is controlled by
          <command>number_of_parallel_trajectories</command>.</para>
        </example>
        </section>
      </section>
    </section>
    <section xml:id="quickstart.parallelization">
      <title  xml:id="quickstart.parallelization.title">A note on parallelization</title>
      <para>Internally, <productname>Tensorflow</productname> uses a 
      computational graph to represent all operations. Nodes in the graph 
      represent computations and their results and edges represent 
      dependencies between these values, i.e. some may act as input to 
      operations resulting in certain output.</para>
      <para>Because of this internal representation 
      <productname>Tensorflow</productname> has two kind of parallelisms:
      <itemizedlist>
        <listitem>inter ops</listitem>
        <listitem>intra ops</listitem>
      </itemizedlist>
      Each is connected to its its own thread pool. Both the command-line
      and the Python interface let you pick the number of threads per pool.
      If 0 is stated (default), then the number of threads is picked 
      automatically.</para>
      <para>In general, <quote>inter_ops_threads</quote>refers to multiple
      cores performing matrix multiplication or reduction operations together.
      <quote>intra_ops_threads</quote> seems to be connected to executing
      multiple nodes in parallel that are independent of each other but this is
      guessing at the moment.</para>
      <warning>
        <para>When setting <quote>inter_ops_threads</quote> 
        <emphasis>unequal</emphasis> to 1, then subsequent runs may produce
        different results, i.e. results are no longer strictly reproducible.
        According to Tensorflow this is because reduction operations such as
        <command>reduce_sum</command> run non-deterministically on multiple
        cores for sake of speed.</para>
      </warning>
    </section>
    <section xml:id="quickstart.conclusion">
      <title  xml:id="quickstart.conclusion.title">Conclusion</title>
      <para>This has been the very quick introduction into samping done
      on neural network's loss function manifolds. You have to take it
      from here.</para>
    </section>
  </chapter>
  <chapter xml:id="reference">
    <title xml:id="reference.title">The reference</title>
    <section xml:id="reference.concepts">
    <title xml:id="reference.concepts.title">General concepts</title>
    <para>Before we dive into the internals of this program suite, let us
    first introduce some general underlying concepts assuming that the
    reader is only roughly familiar with them. This is not meant as a 
    replacement for the study of more in-depth material but should rather
    be seen as a reminder of the terms and notation that will appear later 
    on.</para>
    <itemizedlist>
      <listitem>
        <emphasis>Dataset</emphasis><para>The dataset contains a fixed number
        of datums of input tuples and output tuples. They are typically 
        referred to as <quote>features</quote> and <quote>labels</quote> in
        the machine learning community. Basically, they are samples taken
        from the unknown function which we wish to approximate using the
        neural network. If the output tuples are binary in each component,
        the approximation problem is called a <quote>classification</quote>
        problem. Otherwise, it is a <quote>regression</quote> problem.</para>
      </listitem>
      <listitem>
        <emphasis>Neural network</emphasis><para>The neural network is a black-box
        representing a certain set of general functions that are efficient in 
        solving classification problems (among others). They are parametrized
        explicitly using weights and biases and implicitly through the topoloy
        of the network (connections of nodes residing in layers) and the
        activation functions used. Moreover, the loss function determines the
        best set of parameters for a given task. </para>
      </listitem>
      <listitem>
        <emphasis>Loss</emphasis><para>The loss function determines for a given
        (labelled) dataset what set of neural network's parameters are best.
        Note that there are losses that do not require labels though.
        Different losses result in different set of parameters. It is a
        high-dimensional manifold that we want to learn and capture using the 
        neural network. It implicitly depends on the given dataset and 
        explicitly on the parameters of the neural network, namely weights and 
        biases. Dual to the loss function is the network's output that 
        explicitly depends on the dataset's current datum (fed into the 
        network) and implicitly on the parameters.</para>
        <para>Most important to understand about the loss is that it is a
        <emphasis>non-convex</emphasis> function and therefore in general does 
        not just have a single minimum. This makes the task of finding a good 
        set of parameters that (globally) minimize the loss difficult as one 
        would have to find each and every minima in this high-dimensional 
        manifold and check whether it is actually the global one.</para>
      </listitem>
      <listitem>
        <emphasis>Momenta and kinetic energy</emphasis><para>Momenta is a concept
        taken over from physics where the parameters are considered as particles
        each in a one-dimensional space where the loss is a potential function 
        whose ( negative) gradient acts as a force onto the particle driving them
        down-hill (towards the local minimum). This force is integrated in a 
        classical Newton's mechanic style, i.e. Newton's equation of motion 
        is discretized with small time steps (similar to the learning rate in 
        Gradient Descent). This gives first rise to/velocity and second to 
        momenta, i.e. second order ordinary differential equation (ODE) 
        split up into a system of two one-dimensional ODEs. There are numerous
        stable time integrators, i.e. velocity Verlet/leapfrog, that are employed
        to propagate both particle position (i.e. the parameter value) and
        its momentum through time. Note that momentum and velocity are actually
        equivalent as usually the mass is set to unity.</para>
      </listitem>
      <listitem>
        <emphasis>Optimizers</emphasis><para>Optimizers are used to drive the
        parameters to the local minimum from a given (random) starting 
        position. GradientDescent (GD) is best known, but there are more
        elaborate Optimizers that use the concept of momentum as well. This
        helps in overcoming flat parts of the manifold where the gradient
        is effectively zero but momentum still drives the particles towards
        the minimum.</para>
      </listitem>
      <listitem>
        <emphasis>Samplers</emphasis><para>The goal of samplers is different than
        the goal of optimizers. Samplers aim at discovering a great deal of the
        manifold, not constraint to the local minimum. Usually, they are 
        started from the local minimum and drive the particles further and
        further out until new minima are found between which potential
        barriers had to be overcome.</para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="reference.neural_networks">
    <title xml:id="reference.neural_networks.title">Neural Networks</title>
    <para>A neural network (NN) is a tool used in the context of machine 
    learning.
    Formally, it is a graph with nodes and edges, where nodes represent
    (simple) functions. The edges represent scalar values by which the
    output of one node is scaled as input to another node.  The scalar value
    is called <emphasis>weight</emphasis> and each node also has a
    constant value, the <emphasis>bias</emphasis>, that does not depend
    on the input of other nodes.
    Nodes are organised in layers and nodes are (mostly) only connected 
    between adjacent layer. 
    Special are the very first layer with input nodes that simply accept 
    input from the user and the very last layer whose output is eventually 
    all that matters.</para>
    <para>Typically, a NN might be used for the task of classification:
    Data is fed into the network's input layer and its output layer has nodes
    equal to the number of classes to be distinguished. This can for example
    be used for image classification.</para>
    <para>The essential task at hand is to determine a good set of 
    parameters, i.e. values for the weights and biases, such that the task
    is performed best with respect to some measure.</para>
    </section>
    <section xml:id="reference.loss">
    <title xml:id="reference.loss.title">The loss function</title>
    <para>At the moment, there are two little utility programs that help in 
    evaluating the loss function given a certain dataset, namely the
    <quote>TATiLossFunctionSampler</quote>. Let us give an example
    call right away.</para>
    <example xml:id="reference.loss.example.trajectory">
      <title>Using TATiLossFunctionSampler on a given trajectory</title>
      <programlisting><xi:include  href="cmdline/lossfunctionsampler-trajectory.sh"  parse="text"  
  xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
    </example>
    <para>It takes as input the dataset file <quote>dataset-twoclusters.csv</quote>
    and either a parameter file <quote>trajectory.csv</quote>. This will
    cause the program the re-evaluate the loss function at the trajectory
    points which should hopefully give the same values as already stored in the
    trajectory file itself.</para>
    <para>However, this may be used with a different dataset file, e.g. the
    testing or validation dataset, in order to evaluate the generalization
    error in terms of the overall accuracy or the loss at the points along the 
    given trajectory.</para>
    <para>Interesting is also the second case, where instead of giving
    a parameters file, we sample the parameter space equidistantly as
    follows:</para>
    <example xml:id="reference.loss.example.grid">
      <title>Using TATiLossFunctionSampler with an equidistant grid</title>
      <programlisting><xi:include  href="cmdline/lossfunctionsampler-grid.sh"  parse="text"  
  xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
    </example>
    <para>Here, sample for each weight in the interval [-5,5] at 11 points 
    (10 + endpoint), and similarly for the weights in the interval [-1,1] at
    5 points.</para>
    <note>For anything but trivial networks the computational cost quickly 
    becomes prohibitively large. However, you may use <quote>fix_parameter</quote>
    to lower the computational cost by choosing a certain subsets of weights
    and biases to sample.</note>
    <example xml:id="reference.loss.example.fix_parameter">
      <title>Using TATiLossFunctionSampler with an equidistant grid and fixing parameters</title>
      <programlisting><xi:include  href="cmdline/lossfunctionsampler-fix_parameter.sh"  parse="text"  
  xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
    </example>
    <para>Moreover, using <quote>exclude_parameters</quote> can be
    used to exclude parameters from the variation, i.e. this subset is kept at
    fixed values read from the file given by <quote>parse_parameters_file</quote>
    where the row designated by the value in <quote>parse_steps</quote> is
    taken.</para>
    <para>This can be used to assess the shape of the loss manifold around
    a found minimum.</para>
    <example xml:id="reference.loss.example.exclude_parameters">
      <title>Using TATiLossFunctionSampler with an equidistant grid and excluding parameters</title>
      <programlisting><xi:include  href="cmdline/lossfunctionsampler-exclude_parameters.sh"  parse="text"  
  xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
    </example>
    <para>Here, we have excluded the second weight, named "w1", from the
    sampling. Note that all weight and all bias degrees of freedom are simply 
    enumerated one after the other when going from the input layer till the 
    output layer.</para>
    <para>Furthermore, we have specified a file containing center points for
    all excluded parameters. This file is of CSV style having a column "step"
    to identify which row is to be used and moreover a column for every 
    (excluded) parameter that is fixed at a value unequal to 0. Note that
    the minima file written by <command>TATiExplorer</command>
    can be used as this centers file. Moreover, also the trajectory files have
    the same structure.</para>
  </section>
  <section xml:id="reference.network">
    <title xml:id="reference.network.title">The learned function</title>
    <para>The second little utility programs does not evaluate the loss function
    itself but the unknown function learned by the neural network depending
    on the loss function, called the <quote>TATiInputSpaceSampler</quote>. 
    In other words, it gives the classification result for data point sampled
    from an equidistant grid. Let us give an example call right away.</para>
    <example xml:id="reference.network.example">
      <title>Using TATiInputSpaceSampler with an equidistant grid</title>
      <programlisting><xi:include  href="cmdline/inputspacesampler.sh"  parse="text"  
  xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
    </example>
    <para>Here, <quote>batch_data_files</quote> is an input file but it does
    not need to be present. (Sorry about that abuse of the parameter as
    usually <quote>batch_data_files</quote> is read-only. Here, it is 
    overwritten!). Namely, it is generated by the utility in that it
    equidistantly samples the input space, using the interval [-4,4] for each
    input dimension and 10+1 samples (points on -4 and 4 included). The
    parameters file <quote>trajectory.csv</quote> now contains the values
    of the parameters (weights and biases) to use on which the learned
    function depends or by, in other words, by which it is parametrized. As
    the trajectory contains a whole flock of these, the <quote>parse_steps</quote>
    parameter tells it which steps to use for evaluating each point on the
    equidistant input space grid, simply referring to rows in said file.</para>
    <note>For anything but trivial input spaces the computational cost quickly 
    becomes prohibitively large. But again <quote>fix_parameters</quote>
    is heeded and can be used to fix certain parameters. This is even necessary
    if parsing a trajectory that was created using some parameters fixed as
    they then will <emphasis>not</emphasis> appear in the set of parameters
    written to file. This will raise an error as the file will contain too few
    values.</note>
  </section>
  <section xml:id="reference.samplers">
    <title xml:id="reference.samplers.title">Samplers</title>
    <para>Samplers are at the core of all exploration. In this section we will
    give a few words on advice on the various samplers implemented in this
    package.</para>
    <para>Naturally, not all of them are equivalent. Some are more robust
    with respect to the choice of the step sizes than others. In general, we
    recommend BAOAB at the moment as it is the most accurate with second order
    convergence for average values over the step width size and even fourth
    order in the high-friction limit.</para>
    
    <section xml:id="reference.samplers.sgld">
      <title xml:id="reference.samplers.sgld.title">Stochastic Gradient Langevin Dynamics</title>
      <para>The 
      <firstterm baseform="SGLD" linkend="SGLD">Stochastic Gradient Langevin Dynamics (SGLD)</firstterm> 
      was proposed by <citation role="REFDB">Welling2011</citation> based on the 
      <firstterm baseform="SGD"  linkend="SGD">Stochastic Gradient Descent (SGD)</firstterm>, 
      which is a variant of the 
      <firstterm baseform="GD"  linkend="GD">Gradient Descent (GD)</firstterm> using only a 
      subset of the dataset for computing gradients. The central idea behind
      <glossterm linkend="SGLD">SGLD</glossterm> was to add an additional noise term whose 
      magnitude then controls the noise induced by the approximate gradients.
      </para>
      <note><glossterm linkend="SGLD">SGLD</glossterm> is very much like 
      <glossterm linkend="SGD">SGD</glossterm> and 
      <glossterm linkend="GD">GD</glossterm> in terms that the 
      <command>step_width</command> needs to be small enough with respect
      to the gradient sizes of your problem.</note>
    </section>

    <section xml:id="reference.samplers.ccadl">
      <title xml:id="reference.samplers.ccadl.title">Covariance Controlled Adaptive Langevin</title>
      <para>This is an extension of
      <glossterm baseform="SGD" linkend="SGD">Stochastic Gradient Descent</glossterm>
      proposed by <citation role="REFDB">Shang2015</citation>. The key idea is 
      to dissipate the extra heat caused by the approximate gradients through
      a suitable thermostat. However, the discretisation used here is not based
      on the (first-order) Euler-Maruyama as <glossterm linkend="SGLD">SGLD</glossterm>
      but on <glossterm linkend="GLA">GLA</glossterm> 2nd order.</para>
      <note><command>sigma</command>  and <command>sigmaA</command> are two
      additional parameters that control the action of the thermostat. 
      Moreover, we require the same parameters as for <glossterm linkend="GLA">GLA</glossterm>
      2nd order.
      </note>
    </section>

    <section xml:id="reference.samplers.gla">
      <title xml:id="reference.samplers.gla.title">Geometric Langevin Algorithms</title>
      <para><firstterm linkend="GLA">GLA</firstterm> results from a first-order splitting
      between the Hamiltonian and the Ornstein-Uhlenbeck parts, see section 
      2.2.3 of <citation role="REFDB">Leimkuhler2015</citation> and also
      <citation role="REFDB">Leimkuhler2012</citation>. It provides
      second order accuracy at basically no extra cost.</para>
      <note>
      <para>All <glossterm linkend="GLA">GLA</glossterm> samplers have two
      more parameters: <command>inverse_temperature</command> (also known as 
      beta) and <command>friction_constant</command> (also known as gamma). 
      Inverse temperature controls the average momentum of each 
      parameter while the friction constant decides over how much of the 
      momentum is replaced by random noise, i.e. the random walker character
      of the trajectory.</para>
      <para>Good values for beta depend on the loss manifold and its barriers
      and need to be find by try&amp;error and the moment.</para>
      </note>
    </section>
    
    <section xml:id="reference.samplers.baoab">
      <title xml:id="reference.samplers.baoab.title">BAOAB</title>
      <para>BAOAB derives from the basic building blocks A (position update),
      B (momentum update), and O (noise update) into which the Langevin
      system is split up. Each step is solved in a separate step. Hence, we
      perform a B step, then an A step, ... and so on. This scheme has 
      second-order accuracy and superb overall accuracy with respect to 
      positions. See <citation role="REFDB">Leimkuhler2012</citation> for
      more details.</para>
      <note>BAOAB has the same two additional parameters as given in the
      <xref linkend="reference.samplers.gla">GLAs</xref></note>
    </section>
    
    <section xml:id="reference.samplers.hmc">
      <title xml:id="reference.samplers.hmc.title">Hamiltonian Monte Carlo</title>
      <para><firstterm linkend="HMC">HMC</firstterm> is based on Hamiltonian
      dynamics instead of Langevin Dynamics. Noise only enters when, after the
      evaluation of an acceptance criterion, the momenta are redrawn randomly.
      It has first been proposed by <citation role="REFDB">Duane1987</citation>.
      </para>
    </section>
    
  </section>
  <section xml:id="reference.exploring">
    <title xml:id="reference.exploring.title">Exploring the manifold</title>
    <para>still empty</para>
  </section>
  <section xml:id="reference.miscellaneous">
    <title xml:id="reference.miscellaneous.title">Miscellaneous</title>
    <section xml:id="reference.miscellaneous.parameter_freeze">
      <title>Freezing parameters</title>
      <para>Sometimes it might be desirable to freeze parameters during
      training or sampling. This can be done as follows:</para>
        <example xml:id="reference.miscellaneous.parameter_freeze.example">
          <title>Fix a parameter using the python interface</title>
          <programlisting><xi:include  href="python/fix_parameter.py"  parse="text"  
      xmlns:xi="http://www.w3.org/2001/XInclude"/></programlisting>
        </example>
      <para>Note that you need to initialize the network without adding training
      or sampling methods, i.e. <quote>setup</quote> is None. Then, we fix the
      parameter where we give its name in full tensorflow parlance. Afterwards,
      we may add sample or training nodes and start training/sampling.</para>
      <note>Single values cannot be frozen but only entire weight matrices or 
      bias vectors per layer at the moment.</note>
    </section>
    <para>still empty</para>
  </section>
</chapter>
  <chapter>
    <title>Acknowledgements</title>
    <para>Thanks to all users of the code!</para>
  </chapter>

</book>
