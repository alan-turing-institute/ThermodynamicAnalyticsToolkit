#!/usr/bin/env @PYTHON@
#
# This a command-line version of some of the features found under
# http://playground.tensorflow.org/
# aimed at comparing steepest descent optimizer with a bayesian
# sampling approach.
#
# (C) Frederik Heber 2017-12-01

import sys

sys.path.insert(1, '@pythondir@')

import argparse
import csv
import logging
import numpy as np

from TATi.datasets.classificationdatasets import ClassificationDatasets as DatasetGenerator
from TATi.common import react_generally_to_options

FLAGS = None


if __name__ == '__main__':
    # setup logging
    logging.basicConfig(stream=sys.stdout, level=logging.WARNING)

    parser = argparse.ArgumentParser()
    # please adhere to alphabetical ordering
    parser.add_argument('--data_type', type=int, default=DatasetGenerator.SPIRAL,
        help='Which data set to use: (0) two circles, (1) squares, (2) two clusters, (3) spiral.')
    parser.add_argument('--dimension', type=int, default=10,
        help='Number P of samples (Y^i,X^i)^P_{i=1} to generate for the desired dataset type.')
    parser.add_argument('--noise', type=float, default=0.,
        help='Amount of noise in [0,1] to use.')
    parser.add_argument('--seed', type=int, default=None,
        help='Seed to use for random number generators.')
    parser.add_argument('--train_data_file', type=str,
        help='training CSV file name.')
    parser.add_argument('--train_test_ratio', type=float, default=0.5,
        help='ratio in [0,1] to split dataset into training and test part.')
    parser.add_argument('--test_data_file', type=str,
        help='testing CSV file name.')
    parser.add_argument('--verbose', '-v', action='count',
        help='Level of verbosity during compare')
    parser.add_argument('--version', action="store_true",
        help='Gives version information')
    FLAGS, unparsed = parser.parse_known_args()

    react_generally_to_options(FLAGS, unparsed)

    # init random: None will use random seed
    if FLAGS.seed is not None:
        np.random.seed(FLAGS.seed)

    print("Generating input data")
    dataset_generator=DatasetGenerator()
    xs, ys = dataset_generator.generate(
        dimension=FLAGS.dimension,
        noise=FLAGS.noise,
        data_type=FLAGS.data_type)

    randomize = np.arange(len(xs))
    #print("Randomized set is "+str(randomize))
    np.random.shuffle(randomize)
    xs[:] = np.array(xs)[randomize]
    ys[:] = np.array(ys)[randomize]

    slice_index = int(FLAGS.dimension * FLAGS.train_test_ratio)

    if FLAGS.train_data_file is not None:
        print("Writing to training file")
        with open(FLAGS.train_data_file, 'w', newline='') as train_data_file:
            csv_writer = csv.writer(train_data_file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            csv_writer.writerow(['x1', 'x2', 'label'])
            for x,y in zip(xs[:slice_index], ys[:slice_index]):
                csv_writer.writerow([x[0], x[1], y[0]])
            train_data_file.close()

    if FLAGS.test_data_file is not None:
        print("Writing to test file")
        with open(FLAGS.test_data_file, 'w', newline='') as test_data_file:
            csv_writer = csv.writer(test_data_file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            csv_writer.writerow(['x1', 'x2', 'label'])
            for x,y in zip(xs[slice_index:], ys[slice_index:]):
                csv_writer.writerow([x[0], x[1], y[0]])
            test_data_file.close()
