#!/usr/bin/env @PYTHON@
#
# This is a command-line parser for CSV data from the dataset. It prints
# all input features
# It is very much based on
# https://stackoverflow.com/questions/40143019/how-to-correctly-read-data-from-csvs-into-tensorflow?noredirect=1&lq=1
#
# (C) Frederik Heber 2017-12-01

import sys, getopt
sys.path.insert(1, '@pythondir@')

import argparse
import functools
import logging
import numpy as np
import tensorflow as tf

import collections

from TATi.common import file_length, \
    decode_csv_line, get_csv_defaults, react_generally_to_options

def main(_):

    defaults = get_csv_defaults(input_dimension=2)
    dataset = tf.data.Dataset.from_tensor_slices(FLAGS.batch_data_files)
    dataset = dataset.flat_map(
        lambda filename: (
            tf.data.TextLineDataset(filename)
            .skip(1)
            .filter(lambda line: tf.not_equal(tf.substr(line, 0,1), '#'))))
    dataset = dataset.map(functools.partial(decode_csv_line, defaults=defaults,
                                            input_dimension=2,
                                            output_dimension=1))

    iterator = dataset.make_initializable_iterator()
    next_element = iterator.get_next()

    sess = tf.Session()
    init_op = tf.group(tf.local_variables_initializer(), tf.global_variables_initializer())
    sess.run(init_op)
    sess.run(iterator.initializer)

    try:
        while True:
            features = sess.run(next_element)
            print(str(features[0])+", "+str(features[1]))
    except tf.errors.OutOfRangeError:
        print('Done training, epoch reached')

if __name__ == '__main__':
    # setup logging
    logging.basicConfig(stream=sys.stdout, level=logging.WARNING)

    parser = argparse.ArgumentParser()
    # please adhere to alphabetical ordering
    parser.add_argument('--batch_data_files', type=str, nargs='+', default=[],
        help='filenames of dataset for training formatted as CSV.')
    parser.add_argument('--batch_size', type=int, default=None,
        help='The number of samples used to divide sample set into batches in one training step.')
    parser.add_argument('--seed', type=int, default=None,
        help='Seed to use for random number generators.')
    parser.add_argument('--verbose', '-v', action='count',
        help='Level of verbosity during compare')
    parser.add_argument('--version', action="store_true",
        help='Gives version information')
    FLAGS, unparsed = parser.parse_known_args()

    react_generally_to_options(FLAGS, unparsed)

    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

