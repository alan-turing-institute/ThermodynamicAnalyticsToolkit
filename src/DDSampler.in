#!/usr/bin/env @PYTHON@

import sys, getopt
sys.path.insert(1, '@pythondir@')

import tensorflow as tf
import numpy as np

from DataDrivenSampler.version import get_package_version, get_build_hash
from DataDrivenSampler.DataDrivenSampler import parse_parameters, sample, setup_output_files
from DataDrivenSampler.common import create_classification_dataset, closeFiles, \
    construct_network_model, get_activations, get_filename_from_fullpath, initialize_config_map

FLAGS = None

def create_resource_variables():
    with tf.variable_scope("accumulate"):
        kinetic_energy_t = tf.get_variable("kinetic", shape=[], trainable=False,
                                           initializer=tf.zeros_initializer,
                                           use_resource=True)
        momenta_t = tf.get_variable("momenta", shape=[], trainable=False,
                                           initializer=tf.zeros_initializer,
                                           use_resource=True)
        gradients_t = tf.get_variable("gradients", shape=[], trainable=False,
                                           initializer=tf.zeros_initializer,
                                           use_resource=True)
        noise_t = tf.get_variable("noise", shape=[], trainable=False,
                                           initializer=tf.zeros_initializer,
                                           use_resource=True)


def main(_):
    config_map = initialize_config_map()

    # init random: None will use random seed
    if FLAGS.seed is not None:
        np.random.seed(FLAGS.seed)

    xinput, x, ds = create_classification_dataset(FLAGS, config_map)

    create_resource_variables()

    activations = get_activations()
    nn = construct_network_model(FLAGS, config_map, x,
                                 hidden_activation=activations[FLAGS.hidden_activation],
                                 output_activation=activations[FLAGS.output_activation],
                                 loss_name=FLAGS.loss)

    csv_writer, trajectory_writer = \
        setup_output_files(FLAGS, nn, config_map)

    print("weight vars: "+str(tf.get_collection(tf.GraphKeys.WEIGHTS)))
    print("bias vars: "+str(tf.get_collection(tf.GraphKeys.BIASES)))

    saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.WEIGHTS)+ \
                            tf.get_collection(tf.GraphKeys.BIASES)+ \
                            tf.get_collection("Variables_to_Save"))

    sess = tf.Session(
        config=tf.ConfigProto(
            intra_op_parallelism_threads = None,
            inter_op_parallelism_threads = 1))

    nn.init_graph(sess)

    if FLAGS.restore_model is not None:
        # Tensorflow DOCU says: initializing is not needed when restoring
        # however, global_variables are missing otherwise for storing kinetic, ...
        #tf.reset_default_graph()

        restore_path = FLAGS.restore_model.replace('.meta', '')
        saver.restore(sess, restore_path)
        print("Model restored from file: %s" % restore_path)

    sample(FLAGS, ds, sess, nn, xinput, csv_writer, trajectory_writer, config_map)

    closeFiles(config_map)

    if FLAGS.save_model is not None:
        save_path = saver.save(sess, FLAGS.save_model.replace('.meta', ''))
        print("Model saved in file: %s" % save_path)

if __name__ == '__main__':
    FLAGS, unparsed = parse_parameters()

    if FLAGS.version:
        # give version and exit
        print(get_filename_from_fullpath(sys.argv[0])+" "+get_package_version()+" -- version "+get_build_hash())
        sys.exit(0)

    print("Using parameters: "+str(FLAGS))

    if FLAGS.sampler not in ["GeometricLangevinAlgorithm_1stOrder", "GeometricLangevinAlgorithm_2ndOrder"] \
        and FLAGS.friction_constant != 0.:
        print("You set friction_constant but only GLA 1st and 2nd order use it.")
        sys.exit(1)

    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)


