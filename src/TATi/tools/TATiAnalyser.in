#!/usr/bin/env @PYTHON@

import sys, getopt
sys.path.insert(1, '@pythondir@')

import argparse
import logging
import numpy as np
import os.path
import pandas as pd
import scipy
import tensorflow as tf

from TATi.version import get_package_version, get_build_hash
from TATi.common import get_filename_from_fullpath, setup_csv_file
from TATi.analysis.parsedrunfile import ParsedRunfile
from TATi.analysis.parsedtrajectory import ParsedTrajectory
from TATi.analysis.averageenergieswriter import AverageEnergiesWriter
from TATi.analysis.averagetrajectorywriter import AverageTrajectoryWriter
from TATi.analysis.diffusionmap import DiffusionMap
from TATi.analysis.freeenergy import FreeEnergy
from TATi.options.commandlineoptions import str2bool

FLAGS = None

output_width=8
output_precision=8

def parse_parameters():
    """ Sets up the argument parser for parsing command line parameters into dictionary

    :return: dictionary with parameter names as keys, unrecognized parameters
    """
    parser = argparse.ArgumentParser()
    # please adhere to alphabetical ordering
    parser.add_argument('--average_run_file', type=str, default=None,
        help='CSV file name to output averages and variances of energies.')
    parser.add_argument('--average_trajectory_file', type=str, default=None,
        help='CSV file name to output averages and variances of all degrees of freedom.')
    parser.add_argument('--diffusion_map_method', type=str, default='vanilla',
        help='Method to use for computing the diffusion map: pydiffmap, vanilla or TMDMap')
    parser.add_argument('--diffusion_map_file', type=str, default=None,
        help='Give file name to write eigenvalues of diffusion map to')
    parser.add_argument('--diffusion_matrix_file', type=str, default=None,
        help='Give file name to write eigenvectors and loss of diffusion map to')
    parser.add_argument('--drop_burnin', type=int, default=0,
        help='How many values to drop at the beginning of the trajectory.')
    parser.add_argument('--every_nth', type=int, default=1,
        help='Evaluate only every nth trajectory point to files, e.g. 10')
    parser.add_argument('--free_energy_file', type=str, default=None,
        help='Give file name ending in "-ev_1.csv" to write free energy over bins per eigenvector to')
    parser.add_argument('--inverse_temperature', type=float, default=None,
        help='Inverse temperature at which the sampling was executed for target Boltzmann distribution')
    parser.add_argument('--landmarks', type=int, default=None,
        help='How many landmark points to computer for the trajectory (if any)')
    parser.add_argument('--landmark_file', type=str, default=None,
        help='Give file name ending in "-ev_1.csv" to write trajectory at obtained landmark points per eigenvector to')
    parser.add_argument('--number_of_eigenvalues', type=int, default=4,
        help='How many largest eigenvalues to compute')
    parser.add_argument('--run_file', type=str, default=None,
        help='CSV run file name to read run time values from.')
    parser.add_argument('--steps', type=int, default=20,
        help='How many evaluation steps for averages to take')
    parser.add_argument('--trajectory_file', type=str, default=None,
        help='CSV trajectory file name to read trajectories from and compute diffusion maps on.')
    parser.add_argument('--use_reweighting', type=str2bool, default=False,
        help='Use reweighting of the kernel matrix of diffusion maps by the target distribution.')
    parser.add_argument('--version', '-V', action="store_true",
        help='Gives version information')
    return parser.parse_known_args()


def main(_):
    print("Run file is "+str(FLAGS.run_file))
    if FLAGS.run_file is not None:
        # load run file
        runfile = ParsedRunfile(FLAGS.run_file, FLAGS.every_nth)
        if not runfile.add_drop_burnin(FLAGS.drop_burnin):
            sys.stderr.write("FLAGS.drop_burnin is too large, no data points left.")
            sys.exit(1)

        print("%d steps after dropping burn in." % (runfile.number_steps()))
        print("%lg average and %lg variance in runfile.get_loss()." % \
                (np.average(runfile.get_loss()), runfile.get_loss().var()))

        if FLAGS.average_run_file is not None:
            avg_writer = AverageEnergiesWriter(runfile, FLAGS.steps)
            avg_writer.write(FLAGS.average_run_file)

    print("Trajectory file is "+str(FLAGS.trajectory_file))
    if FLAGS.trajectory_file is not None:
        # load trajectory file
        trajectory = ParsedTrajectory(FLAGS.trajectory_file, FLAGS.every_nth)
        if not trajectory.add_drop_burnin(FLAGS.drop_burnin):
            sys.stderr.write("FLAGS.drop_burnin is too large, no data points left.")
            sys.exit(1)

        if FLAGS.average_trajectory_file is not None:
            averagewriter = AverageTrajectoryWriter(trajectory.get_trajectory())
            averagewriter.write(FLAGS.average_trajectory_file)

        # compute diffusion map and write to file
        if FLAGS.diffusion_map_file is not None or FLAGS.diffusion_matrix_file is not None \
                or FLAGS.landmarks is not None:
            if FLAGS.inverse_temperature is None or FLAGS.number_of_eigenvalues is None:
                print("Require both inverse_temperature and number_of_eigenvalues.")
                sys.exit(255)

            dmap = DiffusionMap.from_parsedtrajectory(trajectory)
            if not dmap.compute(number_eigenvalues=FLAGS.number_of_eigenvalues,
                                inverse_temperature=FLAGS.inverse_temperature,
                                diffusion_map_method=FLAGS.diffusion_map_method,
                                use_reweighting=FLAGS.use_reweighting):
                logging.warning("Diffusion Map computation failed, not computing landmarks.")
                FLAGS.landmarks = 0

            if FLAGS.diffusion_map_file is not None and not os.path.isfile(FLAGS.diffusion_map_file):
                print("Eigenvalues are "+str(dmap.values))
                dmap.write_values_to_csv(FLAGS.diffusion_map_file, output_precision, output_width)

            if FLAGS.diffusion_matrix_file is not None and not os.path.isfile(FLAGS.diffusion_matrix_file):
                dmap.write_vectors_to_csv(FLAGS.diffusion_matrix_file, output_precision, output_width)

            freeenergy = None
            if FLAGS.landmark_prefix is not None and FLAGS.landmarks > 0:
                if freeenergy is None:
                    freeenergy = FreeEnergy(trajectory, dmap)
                freeEnergies, levelsets = freeenergy.compute_on_levelsets( \
                    num_landmarks=FLAGS.landmarks)

                landmarks = dmap.compute_landmarks(FLAGS.landmarks)

                steps = trajectory.get_steps()
                for ev_index in range(np.shape(dmap.vectors)[1]):
                    landmark_filename = FLAGS.landmark_prefix + "-ev_" + str(ev_index + 1) + ".csv"
                    freeenergy.write_levelsets_to_csv( \
                        steps=steps,
                        ev_index=ev_index,
                        landmarks=landmarks[ev_index],
                        freeEnergies=freeEnergies[ev_index],
                        landmark_filename=landmark_filename,
                        output_width=output_width, output_precision=output_precision)

            if FLAGS.free_energy_prefix is not None:
                if freeenergy is None:
                    freeenergy = FreeEnergy(trajectory, dmap)
                freeEnergies, HistogramBins = freeenergy.compute_by_histogramming( \
                    num_bins = FLAGS.landmarks)
                for ev_index in range(len(freeEnergies)):
                    filename = FLAGS.free_energy_prefix + "-ev_" + str(ev_index + 1) + ".csv"
                    freeenergy.write_histograms_to_csv(freeEnergies[ev_index], HistogramBins[ev_index], filename,
                        output_width=output_width, output_precision=output_precision)


if __name__ == '__main__':
    # setup logging
    logging.basicConfig(stream=sys.stdout, level=logging.WARNING)

    FLAGS, unparsed = parse_parameters()

    if FLAGS.version:
        # give version and exit
        print(get_filename_from_fullpath(sys.argv[0])+" "+get_package_version()+" -- version "+get_build_hash())
        sys.exit(0)

    # obtain prefix from given filename
    if FLAGS.landmark_file is not None:
        landmark_suffix = "-ev_1.csv"
        if landmark_suffix in FLAGS.landmark_file:
            FLAGS.landmark_prefix = FLAGS.landmark_file[0:FLAGS.landmark_file.find(landmark_suffix)]
        else:
            FLAGS.landmark_prefix = FLAGS.landmark_file
    else:
        FLAGS.landmark_prefix = None
    if FLAGS.free_energy_file is not None:
        free_energy_suffix = "-ev_1.csv"
        if free_energy_suffix in FLAGS.free_energy_file:
            FLAGS.free_energy_prefix = FLAGS.free_energy_file[0:FLAGS.free_energy_file.find(free_energy_suffix)]
        else:
            FLAGS.free_energy_prefix = FLAGS.free_energy_file
    else:
        FLAGS.free_energy_prefix = None

    print("Using parameters: "+str(FLAGS))

    if len(unparsed) != 0:
        print("There are unparsed parameters '"+str(unparsed)+"', have you misspelled some?")
        sys.exit(255)

    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

