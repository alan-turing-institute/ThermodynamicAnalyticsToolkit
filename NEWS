v0.9
====

- added simulation module, an easy-to-use python interface to loss manifold
  sampling for neural networks.
- large rewrite of userguide, now in asciidoc.
- added programmer's guide
- added roadmap.
- option types are checked in python interface.
- tensorflow up to 1.8 supported.
- improved input pipeline (and thereby overall) performance.
- several smaller fixes.
- HMC is removed temporarily till being fully validated.

v0.8
====

- introducing replicated neural networks to allow for multiple walkers that
  proceed in parallel on individual trajectories with the ability to exchange
  information, e.g. for Ensemble Quasi Newton method.
- Updated package dependencies and funding notes in README.
- Added python interface that allows to use neural network as a general
  function depending parameters and with a gradient.
- FIX: TATiExplorer could still experience dead-locks.
- Docbook now also supports non-standard fop and xsltproc installation paths.
- FIX: scipy.sparse's linalg module was not loaded correctly for certain scipy
  versions.
- added Covariance Controlled Adaptive Langevin (CCAdL) as sampler, untested.
- added option burnin to drop initial set of steps from accumulated averages
- added option progress to display a progress bar with time estimate
- added option summaries_path to write summaries for TensorBoard on demand
- FIX: accuracy was not calculated correctly for multi class classification.
- added testsuite section on tensorflow (non-)capabilities.

v0.7
====
- renamed from DataDrivenSampler (DDS) to Thermodynamic Analytics Toolkit 
  (TATi)
- added (vectorized) hessian and gradient nodes to allow easy access through
  numpy arrays
- sampler, optimizer, lossfunctionsampler, and inputspacesampler may now parse
  parameters from a given CSV file through a single cmd-line option
- Explorer can now run parallel processes each sampling or training along a
  independent trajectory
- FIX: Sampler module's names were inconsistent
- FIX: sqlite3 presence check was broken

v0.6
====

- supporting now up to tensorflow 1.6
- added DDSExplorer for exploring loss landscapes, picking minima long the way
- prints replaced by logging expressions and verbose cmdline statment supported
- FIX: rejection_rate in HMC fixed
- tensorflow computations can now be done with a given basetype.
- returned to default tf.float32 as tensorflow basetype. tf.float64 seems to
  be broken to some extent suggested from sampler's convergence plots
- FIX: SGLD was not resetting aggregated values in run info
- LossFunctionSampler can now fix partial set of parameters and to values
  obtained from (minima, trajectory) file
- FIX: Picking input columns (e.g. "sin(x1)") was broken to some extent
- LossFunctionSampler and InputSpaceSampler can now interpret CSV files of
  arbitrary type (they pick out the columns they need)
- updated userguide significantly
- some fixes to changed dependent python packages related to Ubuntu 16.04

v0.5
====

- may read TFRecords (as well as CSV) files
- added example for MNIST optimization
- input pipelines now depend on tf.Dataset framework. Either in-memory for
  smaller datasets or file
- priors have been added for BAOAB and HMC
- version now always gives a git hash (of the commit)
- Python API can feed its own in-memory dataset for sampling or optimization

v0.4
====

- this is a maintenance release to prepare for tensorflow 1.4. Due to a f***up
  it remains untested on tensorflow 1.3
- made robust for use with tensorflow 1.4 (from tensorflow 1.3.1)
- fixes to HamiltonianMonteCarlo (rejection_rate, non-linear scaling)
- using control_dependencies
- introducing and using NumericalDiff (replacing exact diff in tests)

v0.3
====

- added HamiltonianMonteCarlo sampler
- added BAOAB sampler
- parameters can be fixed in optimization or sampling (also loss function
  sampling)
- FIX: trajectories are now correctly written also for networks with hidden
  layers
- diffusion map analysis can now use python package pydiffmap (and is 
  recommended due to optimal epsilon choice)
- all cmdline examples in userguide are also fully tested
- added input space sampler to see classification boundaries of network
- we no longer generate datasets in memory but parse from CSV files
- added DatasetWriter to produce CSV for old in-memory datasets

v0.2
====

- enhanced userguide with fully tested python examples
- using double floating point precision by default
- allowed external setting of inter and intra ops thread number for 
  parallelizaton
- distributable tarball is working (make dist), target distcheck not yet
- added measuring of execution times (init, train, overall)
- FIX: batch_size went missing
- FIX: Dataset was not shuffled properly and split into test/train inconsistent
- added loss manifold sampler
- added Python interface
- added userguide
- added saving and restoring of neural network model to and from file.
- added trajectory analyser for average parameters and diffusion map analysis
  based on the contributed code by Zofia Trstanova
- added sampling of average kinetic energy and configurational temperature,
  accurate by accumulating in every step (not just "every_nth" step)
- added autotools testsuite
- added SGLD, Geometric Langevin Algorithm 1st and 2nd order sampling


v0.1
====

- gradient descent, SGD, and SGLD optimization
- datasets confined to ones from TensorFlow "playground"
- trajectory analyser
