{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a perceptrons as the neural network\n",
    "\n",
    "In this part we are going to set up a network and look in detail at its loss function, its activation function and how to control its topology.\n",
    "\n",
    "> At the moment TATi can only setup multi-layer perceptrons. We may come to this in the very end.\n",
    "\n",
    "Let's start by importing TATis's `simulation` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TATi.simulation as tati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulation` module is an especially *light-weight*, yet powerful interface to TATi.\n",
    "\n",
    "> Although the class name is `Simulation` (inside a module `simulation`), we will refer to it as `tati` here.\n",
    "\n",
    "Let us take a look at its *docstring*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It relies on a `dict` of **options**. These options control every aspect of TATi: the network, the dataset, how and what files are written, ...\n",
    "\n",
    "Moreover, it offers a set of functions that perform specific tasks like fitting, sampling, ...\n",
    "Finally, there are a data descriptors that grant access to network internals.\n",
    "\n",
    "At the moment, we concentrate on the options.\n",
    "\n",
    "A specific command `tati.help()` lists all available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tati.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not go through all of them, but let's at least take a closer look at one of them: **hidden_dimension**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tati.help(\"hidden_dimension\")   # mind that the option name needs to be a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have the option's name, a brief description, its type and the default value. Here, **hidden_dimension** has an empty list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer perceptron\n",
    "\n",
    "Perceptrons have the following properties:\n",
    "\n",
    "- input layer dimension\n",
    "- output layer dimension\n",
    "- number of hidden layers and their dimension\n",
    "- additional drop-out layers\n",
    "- activation function per node\n",
    "- loss function\n",
    "\n",
    "Each of these properties can be tuned with one of the options above.\n",
    "\n",
    "The whole network is set up by instantiating `tati` with a given set of options. We can simply pass the options whose default value we want to change, by giving them as *keyword arguments (kwargs)* to the constructor of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=0,\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, we made a mistake! ... rats, what was again the type of **hidden_dimension**?\n",
    "\n",
    "Of course, we knew already that it needs to be a list of ints. Then, let's fix the above instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=[0],\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single-layer perceptron should have three degrees of freedom, let's check using `num_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dataset* is an essential part of the network. Its dimensions define type and number of input and output nodes. Therefore, the network is internally *constructed first when a dataset is provided*.\n",
    "\n",
    "Let us provide a dummy dataset through the option `dataset` and check again for the number of degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the correct results, two weights and a single bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the the options\n",
    "\n",
    "In case you are curious about the options inside `tati`, use `get_options()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.get_options())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, options are stored in private variable `_options`.\n",
    "\n",
    "> *WARNING:* Do not use `nn._options[\"input_dimension\"]=3` directly, rather use `tati.set_options()`.\n",
    "\n",
    "This is because some options severely affect the network topology to the effect that the network is reinstantiated. `setup_options()` takes this into account ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_options(input_dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and properly warns you in case the change is too severe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing degrees of freedom\n",
    "\n",
    "Consider the case where we only want a network with two weights and no bias. The bias is removed if we set it to zero. How can we fix the single bias to this value?\n",
    "\n",
    "> Fixing the bias is essentially changing the network, hence we need to add this parameter at the start. Let's reinstantiate `tati`.\n",
    "\n",
    "When reinstantiating `tati`, the internal graph of tensorflow is reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          fix_parameters=\"output/biases/Variable:0=0.\",\n",
    "          hidden_dimension=[0],\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")\n",
    "\n",
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the critical change! The bias degree of freedom has been effectively removed.\n",
    "\n",
    "The above string `output/biases/Variable:0=0.` needs some explanation. The string addresses a particular variable inside tensorflow, namely `Variable:0` in the name scopes `biases` and `output`. Moreover, we assign (\"=\") this variable the fixed value of *0.*. In case you want to fix a weight, replace `biases` by `weights`. In case it is the first hidden layer, user `layer1` in place of `output`. If the name cannot be found, you'll get a helpful error message. \n",
    "\n",
    "> There need to be as many values as the variables has components (comma-separated list). Moreover, it is not possible to fix single components. At the moment only all weights of a layer or all biases of a layer can be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron\n",
    "\n",
    "Let us return to `set_options()` and changing *hidden_dimension*.\n",
    "\n",
    "What do you do in case you really want a different network? You need to reinstantiate `tati` with the different set of options. This will automatically reset tensorflow's internal computational graph.\n",
    "\n",
    "> Therefore, you cannot have two instances of `tati` at the same time.\n",
    "\n",
    "Let's add two hidden layers, each with 8 nodes. Moreover, we want to use the *sigmoid* function for activation. Finally, we need to use the cross entropy function with softmax as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=[8, 8],\n",
    "          hidden_activation=\"sigmoid\", output_activation=\"relu\",\n",
    "          loss=\"softmax_cross_entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the number of degrees of freedom - note this is less tedious once you see how to pass a dataset easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly check whether this is true: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2*8+8*8+8*1+8+8+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems correct.\n",
    "\n",
    "This is all about the setting up of the network. Next we will be looking at specifying the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- `Simulation` module's principal design: **options**, a set of *functions*, a few data *descriptors*.\n",
    "- how to get help on `Simulaton` and its set of *options*.\n",
    "- a dataset is stricly necessary to actually use a neural network (lazy construction).\n",
    "- how to set up a single-layer perceptron and a multi-layer perceptron."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
