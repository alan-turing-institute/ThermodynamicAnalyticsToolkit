{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding a sampling loop\n",
    "\n",
    "Here, we want to write a sampling loop using the `Model` class. This will take us into the intrinsics of `tensorflow`, with its `Session` object that requires a `feed_dict` to evaluate nodes. Moreover, we will understand that `Model` is essentially just a bit init() function and a dictionary to get at the initiated nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TATi.model import Model as tati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's go through this a bit quicker.\n",
    "\n",
    "#### Instantiate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TATi.options.pythonoptions import PythonOptions\n",
    "\n",
    "options = PythonOptions()\n",
    "options.set_options(\n",
    "    batch_data_files=[\"dataset-twoclusters.csv\"],\n",
    "    fix_parameters=\"output/biases/Variable:0=-0.045677684\",\n",
    "    friction_constant=1.,\n",
    "    inverse_temperature=10.,\n",
    "    output_activation=\"linear\",\n",
    "    loss=\"mean_squared\",\n",
    "    max_steps=100,\n",
    "    parse_parameters_file=\"training.csv\",\n",
    "    parse_steps=[100],\n",
    "    sampler=\"BAOAB\",\n",
    "    seed=426,\n",
    "    step_width=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tati(options)\n",
    "nn.init_input_pipeline()\n",
    "nn.init_network(None, setup=\"sample\")\n",
    "\n",
    "# reset dataset to set its \"iterator\" to start\n",
    "nn.reset_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The loop\n",
    "\n",
    "Before we create the loop, we need to fill a `feed_dict`. This is a dictionary with values for every `tensorflow.placeholder` node. As the name suggest, these are placeholders for values fed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    nn.state.nn[0].placeholder_nodes[\"friction_constant\"]: options.friction_constant,\n",
    "    nn.state.nn[0].placeholder_nodes[\"inverse_temperature\"]: options.inverse_temperature,\n",
    "    nn.state.nn[0].placeholder_nodes[\"step_width\"]: options.step_width,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we gather a list of nodes which we want to evaluate per step. Among them is `sample_step`, that triggers the a single update step as implemented by the *BAOAB* sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_nodes = [nn.state.nn[0].get(item) for item in [\"sample_step\", \"accuracy\", \"global_step\", \"loss\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we loop for `max_steps` steps: In the loop we evaluate a specific node,  For this, however, we need the feed_dict contain the batch's features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(options.max_steps):\n",
    "    # place the batch inside feed_dict\n",
    "    features, labels = nn.state.input_pipeline.next_batch(nn.sess)\n",
    "    feed_dict.update({\n",
    "        nn.state.xinput: features,\n",
    "        nn.state.true_labels: labels\n",
    "    })\n",
    "    \n",
    "    # perform the sampling step\n",
    "    _, acc, step, loss = nn.sess.run(step_nodes, feed_dict=feed_dict)\n",
    "    \n",
    "    # print loss\n",
    "    print(step, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- `Model` captures its state in the `ModelState`. In that state there is an instance of `NeuralNetwork`, one per walker.\n",
    "- sampling is triggered by evaluating a specific node `sample_step`.\n",
    "- evaluation of nodes requires a `Session` object and for each required `tensorflow.placeholder` an entry in a so-called `feed_dict`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
