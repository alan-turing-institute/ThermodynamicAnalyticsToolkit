{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a perceptrons as the neural network\n",
    "\n",
    "In this part we are going to set up a network and look in detail at its loss function, its activation function and how to control its topology.\n",
    "\n",
    "> At the moment TATi can only setup multi-layer perceptrons. We may come to this in the very end.\n",
    "\n",
    "Let's start by importing TATis's `simulation` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TATi.simulation as tati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulation` module is an especially *light-weight*, yet powerful interface to TATi.\n",
    "\n",
    "> Although the class name is `Simulation` (inside a module `simulation`), we will refer to it as `tati` here.\n",
    "\n",
    "Let us take a look at its *docstring*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Simulation in module TATi.simulation:\n",
      "\n",
      "class Simulation(builtins.object)\n",
      " |  This class represents the Python interface to TATi that allows to\n",
      " |    access the neural network (including its loss function, parameters,\n",
      " |    ...) as a black-box function.\n",
      " |    \n",
      " |    The idea is that there is no need to worry about any of the neural\n",
      " |    network internals. An initial parameter structure is all that is\n",
      " |    needed and afterwards one may treat the whole thing as two (coupled)\n",
      " |    functions, namely the loss and the predictor, where the loss depends\n",
      " |    implicitly on the dataset and both use the set of parameters of the\n",
      " |    neural network.\n",
      " |  \n",
      " |    The whole setup is steered through an extensive options dict, typically\n",
      " |    called *FLAGS* or\n",
      " |  \n",
      " |  Let us give a brief example of how to use the class. For more\n",
      " |  extensive use cases we refer to the userguide that accompanies this\n",
      " |  software package.\n",
      " |  \n",
      " |  Here, we use a dataset contained in the CSV file `dataset.cvs`\n",
      " |  which contains feature columns [\"x1\", \"x2\", ...] and label\n",
      " |  columns [\"label1\", \"label2\", ...]. We use the `GradientDescent`\n",
      " |  optimizer for 1000 steps with a learning rate of 0.1. The\n",
      " |  call to `fit()` runs the actual training. Once done, we have\n",
      " |  a look at the resulting loss and the parameters of the network.\n",
      " |  \n",
      " |    Example:\n",
      " |      from TATi.simulation import Simulation\n",
      " |      nn = Simulation(\n",
      " |        batch_data_files=\"dataset.csv\",\n",
      " |        max_steps=1000,\n",
      " |        optimizer=\"GradientDescent\",\n",
      " |      learning_rate=0.1)\n",
      " |      nn.fit()\n",
      " |      print(\"Loss: \" + str(nn.loss()) + \" for parameter set: \" + str(nn.parameters))\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Initializes the internal neural network and everything.\n",
      " |      \n",
      " |      Args:\n",
      " |        kwargs: for full options, see `PythonOptions._description_map`.\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  fit(self, walker_index=0)\n",
      " |      Fits the parameters of the neural network to best match with the\n",
      " |      given dataset.\n",
      " |      \n",
      " |      Note that the parameters of the fit such as `optimizer`,\n",
      " |      `learning_rate` are all set in the `__init__()` options statement and\n",
      " |      may be changed through `set_options()`.\n",
      " |      \n",
      " |      Args:\n",
      " |        walker_index: index of walker to use for fitting (Default value = 0)\n",
      " |      \n",
      " |      Returns:\n",
      " |        `TrajectoryData` instance containing run_info, trajectory, averages\n",
      " |        pandas dataframes\n",
      " |  \n",
      " |  gradients(self, walker_index=None)\n",
      " |      Evaluates the gradient of the loss with respect to the set\n",
      " |      of parameters at the current parameters.\n",
      " |      \n",
      " |      For sake of speed, the parameters have to be set beforehand.\n",
      " |      \n",
      " |      Args:\n",
      " |        walker_index: index of walker to use for fitting or None for all (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        gradients for walker `walker_index`\n",
      " |  \n",
      " |  hessians(self, walker_index=None)\n",
      " |      Evaluates the hessian of the loss with respect to the\n",
      " |      set of parameters at the current parameters.\n",
      " |      \n",
      " |      For sake of speed, the parameters have to be set beforehand.\n",
      " |      \n",
      " |      Args:\n",
      " |        walker_index: index of walker to use for fitting or None for all (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        hessian for walker `walker_index`\n",
      " |  \n",
      " |  init_momenta(self, inverse_temperature=None)\n",
      " |      Reinitializes the network parameter's momenta from gaussian distribution\n",
      " |      with `inverse_temperature` as stddev and 0 mean.\n",
      " |      \n",
      " |      Note:\n",
      " |          This uses numpy's standard_normal to initialize.\n",
      " |          Set `numpy.random.seed()` to obtain reproducible runs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inverse_temperature: inverse temperature for momenta scaling or None for default\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  loss(self, walker_index=None)\n",
      " |      Evalutes the current loss.\n",
      " |      \n",
      " |      Args:\n",
      " |        walker_index: index of walker to use or None for all (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        value of the loss function for walker `walker_index`\n",
      " |  \n",
      " |  num_parameters(self)\n",
      " |      Returns the number of parameters of the neural network.\n",
      " |      \n",
      " |      Returns:\n",
      " |          number of parameters/degrees of freedom of the network\n",
      " |  \n",
      " |  num_walkers(self)\n",
      " |      Returns the number of replicated copies of the neural network, i.e. walkers\n",
      " |      \n",
      " |      Returns:\n",
      " |          number of walkers/replicated copies of the network\n",
      " |  \n",
      " |  predict(self, features, walker_index=0)\n",
      " |      Evaluates predictions (i.e. output of network) for the given features.\n",
      " |      \n",
      " |      Args:\n",
      " |        features: feature array to predict labels for\n",
      " |        walker_index: index of walker to use for prediction (Default value = 0)\n",
      " |      \n",
      " |      Returns:\n",
      " |        labels for `features` predicted by walker `walker_index`\n",
      " |  \n",
      " |  sample(self)\n",
      " |      Performs sampling of the neural network's loss manifold for all walkers.\n",
      " |      \n",
      " |      Note:\n",
      " |          The parameters of the sampling such as `sampler`, `step_width`\n",
      " |          are all set in the `__init__()` options statement.\n",
      " |      \n",
      " |          At the moment, this function will perform sampling for all walkers\n",
      " |          at once.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `TrajectoryData` instance containing run_info, trajectory, averages pandas\n",
      " |          dataframes\n",
      " |  \n",
      " |  score(self, walker_index=None)\n",
      " |      Evaluates the accuracy on the given dataset\n",
      " |      \n",
      " |      Args:\n",
      " |        walker_index: index of walker to use for fitting (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        accuracy for walker `walker_index`\n",
      " |  \n",
      " |  set_options(self, **kwargs)\n",
      " |      Resets some of the options to new values given by the keyword\n",
      " |      dictionary in `kwargs`.\n",
      " |      \n",
      " |      Warning:\n",
      " |          This may reset the dataset or even the network depending on what\n",
      " |          parameters are changed.\n",
      " |      \n",
      " |      Args:\n",
      " |        kwargs: any option listed in `Simulation._affects_map`\n",
      " |      \n",
      " |      Returns:\n",
      " |        None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_activations()\n",
      " |      List the names of all available activation functions.\n",
      " |      \n",
      " |      Returns:\n",
      " |        list of all valid activation names\n",
      " |  \n",
      " |  get_losses()\n",
      " |      List the names of all available loss functions.\n",
      " |      \n",
      " |      Returns:\n",
      " |        list of all valid loss names\n",
      " |  \n",
      " |  help(key=None)\n",
      " |      Prints help for each option or all option names if key is None\n",
      " |      \n",
      " |      Args:\n",
      " |        key: name of option or None for list of options (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  dataset\n",
      " |      Getter for the dataset as a numpy array with respect to the\n",
      " |      currently chosen `batch_size`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          array of features and labels, each a numpy array of `batch_size`\n",
      " |  \n",
      " |  momenta\n",
      " |      Returns the current momentum to each parameter.\n",
      " |      \n",
      " |      Returns:\n",
      " |          momenta or None if sampler does not support momenta\n",
      " |  \n",
      " |  parameters\n",
      " |      Returns the current set of parameters\n",
      " |      \n",
      " |      Returns:\n",
      " |          parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It relies on a `dict` of **options**. These options control every aspect of TATi: the network, the dataset, how and what files are written, ...\n",
    "\n",
    "Moreover, it offers a set of functions that perform specific tasks like fitting, sampling, ...\n",
    "Finally, there are a data descriptors that grant access to network internals.\n",
    "\n",
    "At the moment, we concentrate on the options.\n",
    "\n",
    "A specific command `tati.help()` lists all available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averages_file:             CSV file name to write ensemble averages information such as average kinetic, potential, virial\n",
      "batch_data_file_type:      type of the files to read input from\n",
      "batch_data_files:          set of files to read input from\n",
      "batch_size:                The number of samples used to divide sample set into batches in one sampleing step.\n",
      "burn_in_steps:             number of initial steps to drop when computing averages\n",
      "collapse_walkers:          Whether to regularly collapse all dependent walkers to restart from a single position again, maintaining harmonicapproximation for ensemble preconditioning. 0 will not collapse.\n",
      "covariance_after_steps:    Number of steps after which to regularly recompute the covariance matrix. This will require communication between the walkers. 0 will never compute a covariance matrix.\n",
      "covariance_blending:       mixing for preconditioning matrix to gradient update, identity matrix plus this times the covariance matrix obtained from the other walkers, 0 - will never collapse\n",
      "diffusion_map_method:      name of method to use for diffusion map analysis: vanilla, TMDap, pydiffmap\n",
      "directions_file:           CSV file name to parse directions spanning subspace to project trajectories onto\n",
      "do_hessians:               whether to add hessian evaluation nodes to graph, used by optimzier and explorer\n",
      "dropout:                   Keep probability for sampleing dropout, e.g. 0.9\n",
      "every_nth:                 Store only every nth trajectory (and run) point to files, e.g. 10\n",
      "fix_parameters:            string formatted as 'name=value;...' with name of parameter fixed to value\n",
      "friction_constant:         friction to scale the influence of momenta\n",
      "hamiltonian_dynamics_time: time w.r.t step_width for HMC sampler passing between checking acceptance criterion\n",
      "hidden_activation:         Activation function to use for hidden layer: tanh, relu, linear\n",
      "hidden_dimension:          Dimension of each hidden layer, e.g. 8 8 for two hidden layers each with 8 nodes fully connected\n",
      "in_memory_pipeline:        whether to feed the dataset from file in-memory (True) or not (False)\n",
      "input_columns:             Pick a list of the following: (1) x1, (2) x2, (3) x1^2, (4) x2^2, (5) sin(x1), (6) sin(x2).\n",
      "input_dimension:           number of input nodes/number of features\n",
      "inter_ops_threads:         size of thread pool used for independent ops\n",
      "intra_ops_threads:         size of thread pool used for parallelizing an op\n",
      "inverse_temperature:       Inverse temperature that scales the gradients\n",
      "learning_rate:             learning rate used during optimization, see also `step_width`\n",
      "loss:                      Set the loss to be measured during sampling, e.g. mean_squared, log_loss, ...\n",
      "max_steps:                 Number of steps to run sampleer.\n",
      "number_of_eigenvalues:     \n",
      "number_walkers:            number of dependent walkers to activate ensemble preconditioning\n",
      "optimizer:                 Choose the optimizer to use for sampling: GradientDescent\n",
      "output_activation:         Activation function to use for output layer: tanh, relu, linear\n",
      "output_dimension:          number of output nodes/number of classes\n",
      "parse_parameters_file:     parse neural network parameters from this file on network creation\n",
      "parse_steps:               indicates the row (in column 'step') of the parse_parameters_file to use\n",
      "prior_factor:              factor for scaling prior force\n",
      "prior_lower_boundary:      lower boundary for wall-repelling prior force\n",
      "prior_power:               power of distance used in calculating force\n",
      "prior_upper_boundary:      upper boundary for wall-repelling prior force\n",
      "progress:                  activate progress bar to show remaining time\n",
      "restore_model:             Restore model (weights and biases) from a file.\n",
      "run_file:                  CSV run file name to runtime information such as output accuracy and loss values.\n",
      "sampler:                   Choose the sampler to use for sampling: BAOAB,CovarianceControlledAdaptiveLangevin, GeometricLangevinAlgorithm_1stOrder, GeometricLangevinAlgorithm_2ndOrder, HamiltonianMonteCarlo_1stOrder, HamiltonianMonteCarlo_2ndOrder, StochasticGradientLangevinDynamics\n",
      "save_model:                Save model (weights and biases) to a file for later restoring.\n",
      "seed:                      Seed to use for random number generators.\n",
      "sigma:                     Scale of noise injected to momentum per step for CCaDL.\n",
      "sigmaA:                    Scale of noise in convex combination for CCaDL.\n",
      "sql_db:                    Filename of sqlite3 database file to write iteration information to\n",
      "step_width:                step width \\Delta t to use, e.g. 0.01\n",
      "summaries_path:            path to write summaries (for TensorBoard) to\n",
      "trajectory_file:           CSV file name to output trajectories of sampling, i.e. weights and evaluated loss function.\n",
      "use_reweighting:           \n",
      "verbose:                   how much (debugging) information to print\n"
     ]
    }
   ],
   "source": [
    "tati.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not go through all of them, but let's at least take a closer look at one of them: **hidden_dimension**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option name: hidden_dimension\n",
      "Description: Dimension of each hidden layer, e.g. 8 8 for two hidden layers each with 8 nodes fully connected\n",
      "Type       : list of <class 'int'>\n",
      "Default    : []\n"
     ]
    }
   ],
   "source": [
    "tati.help(\"hidden_dimension\")   # mind that the option name needs to be a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have the option's name, a brief description, its type and the default value. Here, **hidden_dimension** has an empty list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer perceptron\n",
    "\n",
    "Perceptrons have the following properties:\n",
    "\n",
    "- input layer dimension\n",
    "- output layer dimension\n",
    "- number of hidden layers and their dimension\n",
    "- additional drop-out layers\n",
    "- activation function per node\n",
    "- loss function\n",
    "\n",
    "Each of these properties can be tuned with one of the options above.\n",
    "\n",
    "The whole network is set up by instantiating `tati` with a given set of options. We can simply pass the options whose default value we want to change, by giving them as *keyword arguments (kwargs)* to the constructor of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Option hidden_dimension needs to be list of type <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c5aa85b43f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mhidden_dimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mhidden_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           loss=\"mean_squared\")\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/simulation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m## Options dict controlling all options of the network, sampling, ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/options/pythonoptions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, add_keys, value_dict)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvalue_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/options/pythonoptions.py\u001b[0m in \u001b[0;36mset_options\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/options/pythonoptions.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPythonOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/options/options.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     raise ValueError(\"Option %s needs to be list of type %s\" \\\n\u001b[0;32m--> 170\u001b[0;31m                                      %  (key, str(self._list_type_map[key])))\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# option has no designated type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Option hidden_dimension needs to be list of type <class 'int'>"
     ]
    }
   ],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=0,\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, we made a mistake! ... rats, what was again the type of **hidden_dimension**?\n",
    "\n",
    "Of course, we knew already that it needs to be a list of ints. Then, let's fix the above instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=[0],\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single-layer perceptron should have three degrees of freedom, let's check using `num_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Neural network has not been constructed, dataset provided?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-41292b6ab176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/simulation.py\u001b[0m in \u001b[0;36mnum_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \"\"\"\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_weight_dof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_bias_dof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/simulation.py\u001b[0m in \u001b[0;36m_check_nn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neural network has not been constructed, dataset provided?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Neural network has not been constructed, dataset provided?"
     ]
    }
   ],
   "source": [
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dataset* is an essential part of the network. Its dimensions define type and number of input and output nodes. Therefore, the network is internally *constructed first when a dataset is provided*.\n",
    "\n",
    "Let us provide a dummy dataset through the option `dataset` and check again for the number of degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the correct results, two weights and a single bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the the options\n",
    "\n",
    "In case you are curious about the options inside `tati`, use `get_options()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'averages_file': None, 'batch_data_file_type': csv, 'batch_data_files': [], 'batch_size': 1, 'burn_in_steps': 0, 'collapse_walkers': False, 'covariance_after_steps': 100, 'covariance_blending': 0.0, 'diffusion_map_method': vanilla, 'dimension': 1, 'directions_file': None, 'do_hessians': False, 'dropout': None, 'every_nth': 1, 'fix_parameters': None, 'friction_constant': 0.0, 'hamiltonian_dynamics_time': 1.0, 'hidden_activation': linear, 'hidden_dimension': [0], 'in_memory_pipeline': True, 'input_columns': [], 'input_dimension': 2, 'inter_ops_threads': 1, 'intra_ops_threads': None, 'inverse_temperature': 1.0, 'learning_rate': 0.03, 'loss': mean_squared, 'max_steps': 1000, 'number_of_eigenvalues': 4, 'number_walkers': 1, 'optimizer': GradientDescent, 'output_activation': relu, 'output_dimension': 1, 'output_type': binary_classification, 'parse_parameters_file': None, 'parse_steps': [], 'prior_factor': 1.0, 'prior_lower_boundary': None, 'prior_power': 1.0, 'prior_upper_boundary': None, 'progress': False, 'restore_model': None, 'run_file': None, 'sampler': GeometricLangevinAlgorithm_1stOrder, 'save_model': None, 'seed': None, 'sigma': 1.0, 'sigmaA': 1.0, 'sql_db': None, 'step_width': 0.1, 'summaries_path': None, 'trajectory_file': None, 'use_reweighting': False, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print(nn.get_options())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, options are stored in private variable `_options`.\n",
    "\n",
    "> *WARNING:* Do not use `nn._options[\"input_dimension\"]=3` directly, rather use `tati.set_options()`.\n",
    "\n",
    "This is because some options severely affect the network topology to the effect that the network is reinstantiated. `setup_options()` takes this into account ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Changing the network is not yet supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-886c4dbccca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tati_webinar/lib/python3.6/site-packages/TATi/simulation.py\u001b[0m in \u001b[0;36mset_options\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"network\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffected_parts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Changing the network is not yet supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"network\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffected_parts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_nn_construction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Changing the network is not yet supported."
     ]
    }
   ],
   "source": [
    "nn.set_options(input_dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and properly warns you in case the change is too severe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing degrees of freedom\n",
    "\n",
    "Consider the case where we only want a network with two weights and no bias. The bias is removed if we set it to zero. How can we fix the single bias to this value?\n",
    "\n",
    "> Fixing the bias is essentially changing the network, hence we need to add this parameter at the start. Let's reinstantiate `tati`.\n",
    "\n",
    "When reinstantiating `tati`, the internal graph of tensorflow is reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          fix_parameters=\"output/biases/Variable:0=0.\",\n",
    "          hidden_dimension=[0],\n",
    "          hidden_activation=\"linear\", output_activation=\"relu\",\n",
    "          loss=\"mean_squared\")\n",
    "\n",
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the critical change! The bias degree of freedom has been effectively removed.\n",
    "\n",
    "The above string `output/biases/Variable:0=0.` needs some explanation. The string addresses a particular variable inside tensorflow, namely `Variable:0` in the name scopes `biases` and `output`. Moreover, we assign (\"=\") this variable the fixed value of *0.*. In case you want to fix a weight, replace `biases` by `weights`. In case it is the first hidden layer, user `layer1` in place of `output`. If the name cannot be found, you'll get a helpful error message. \n",
    "\n",
    "> There need to be as many values as the variables has components (comma-separated list). Moreover, it is not possible to fix single components. At the moment only all weights of a layer or all biases of a layer can be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron\n",
    "\n",
    "Let us return to `set_options()` and changing *hidden_dimension*.\n",
    "\n",
    "What do you do in case you really want a different network? You need to reinstantiate `tati` with the different set of options. This will automatically reset tensorflow's internal computational graph.\n",
    "\n",
    "> Therefore, you cannot have two instances of `tati` at the same time.\n",
    "\n",
    "Let's add two hidden layers, each with 8 nodes. Moreover, we want to use the *sigmoid* function for activation. Finally, we need to use the cross entropy function with softmax as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tati(input_dimension=2,\n",
    "          output_dimension=1,\n",
    "          hidden_dimension=[8, 8],\n",
    "          hidden_activation=\"sigmoid\", output_activation=\"relu\",\n",
    "          loss=\"softmax_cross_entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the number of degrees of freedom - note this is less tedious once you see how to pass a dataset easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "# mind that features, labels need to be lists of lists\n",
    "nn.dataset = [np.asarray([[0,0]], dtype=np.float32), np.asarray([[1]], dtype=np.int32)]  \n",
    "print(nn.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly check whether this is true: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "print(2*8+8*8+8*1+8+8+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems correct.\n",
    "\n",
    "This is all about the setting up of the network. Next we will be looking at specifying the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- `Simulation` module's principal design: **options**, a set of *functions*, a few data *descriptors*.\n",
    "- how to get help on `Simulaton` and its set of *options*.\n",
    "- a dataset is stricly necessary to actually use a neural network (lazy construction).\n",
    "- how to set up a single-layer perceptron and a multi-layer perceptron."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
